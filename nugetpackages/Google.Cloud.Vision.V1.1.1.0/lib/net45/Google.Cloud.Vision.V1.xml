<?xml version="1.0"?>
<doc>
    <assembly>
        <name>Google.Cloud.Vision.V1</name>
    </assembly>
    <members>
        <member name="T:Google.Cloud.Vision.V1.AnnotateImageException">
            <summary>
            An error occurring when annotating an image.
            </summary>
        </member>
        <member name="P:Google.Cloud.Vision.V1.AnnotateImageException.Response">
            <summary>
            The complete response containing the error.
            </summary>
        </member>
        <member name="M:Google.Cloud.Vision.V1.AnnotateImageException.#ctor(Google.Cloud.Vision.V1.AnnotateImageResponse)">
            <summary>
            Constructs an exception based on the error in <paramref name="response"/>.
            </summary>
            <param name="response">The response containing the error. Must not be null, and the <see cref="P:Google.Cloud.Vision.V1.AnnotateImageResponse.Error"/>
            property must not be null.</param>
        </member>
        <member name="T:Google.Cloud.Vision.V1.AnnotateImageResponse">
            <summary>
            Response to an image annotation request.
            </summary>
        </member>
        <member name="M:Google.Cloud.Vision.V1.AnnotateImageResponse.ThrowOnError">
            <summary>
            If the <see cref="P:Google.Cloud.Vision.V1.AnnotateImageResponse.Error"/> property is non-null, throws an <see cref="T:Google.Cloud.Vision.V1.AnnotateImageException"/>.
            Otherwise, returns <c>this</c> (so that the method can be called in a fluent manner).
            </summary>
            <exception cref="T:Google.Cloud.Vision.V1.AnnotateImageException">The <see cref="P:Google.Cloud.Vision.V1.AnnotateImageResponse.Error"/> property is non-null.</exception>
            <returns><c>this</c> if the message has no error.</returns>
        </member>
        <member name="F:Google.Cloud.Vision.V1.AnnotateImageResponse.FaceAnnotationsFieldNumber">
            <summary>Field number for the "face_annotations" field.</summary>
        </member>
        <member name="P:Google.Cloud.Vision.V1.AnnotateImageResponse.FaceAnnotations">
            <summary>
            If present, face detection has completed successfully.
            </summary>
        </member>
        <member name="F:Google.Cloud.Vision.V1.AnnotateImageResponse.LandmarkAnnotationsFieldNumber">
            <summary>Field number for the "landmark_annotations" field.</summary>
        </member>
        <member name="P:Google.Cloud.Vision.V1.AnnotateImageResponse.LandmarkAnnotations">
            <summary>
            If present, landmark detection has completed successfully.
            </summary>
        </member>
        <member name="F:Google.Cloud.Vision.V1.AnnotateImageResponse.LogoAnnotationsFieldNumber">
            <summary>Field number for the "logo_annotations" field.</summary>
        </member>
        <member name="P:Google.Cloud.Vision.V1.AnnotateImageResponse.LogoAnnotations">
            <summary>
            If present, logo detection has completed successfully.
            </summary>
        </member>
        <member name="F:Google.Cloud.Vision.V1.AnnotateImageResponse.LabelAnnotationsFieldNumber">
            <summary>Field number for the "label_annotations" field.</summary>
        </member>
        <member name="P:Google.Cloud.Vision.V1.AnnotateImageResponse.LabelAnnotations">
            <summary>
            If present, label detection has completed successfully.
            </summary>
        </member>
        <member name="F:Google.Cloud.Vision.V1.AnnotateImageResponse.TextAnnotationsFieldNumber">
            <summary>Field number for the "text_annotations" field.</summary>
        </member>
        <member name="P:Google.Cloud.Vision.V1.AnnotateImageResponse.TextAnnotations">
            <summary>
            If present, text (OCR) detection has completed successfully.
            </summary>
        </member>
        <member name="F:Google.Cloud.Vision.V1.AnnotateImageResponse.FullTextAnnotationFieldNumber">
            <summary>Field number for the "full_text_annotation" field.</summary>
        </member>
        <member name="P:Google.Cloud.Vision.V1.AnnotateImageResponse.FullTextAnnotation">
            <summary>
            If present, text (OCR) detection or document (OCR) text detection has
            completed successfully.
            This annotation provides the structural hierarchy for the OCR detected
            text.
            </summary>
        </member>
        <member name="F:Google.Cloud.Vision.V1.AnnotateImageResponse.SafeSearchAnnotationFieldNumber">
            <summary>Field number for the "safe_search_annotation" field.</summary>
        </member>
        <member name="P:Google.Cloud.Vision.V1.AnnotateImageResponse.SafeSearchAnnotation">
            <summary>
            If present, safe-search annotation has completed successfully.
            </summary>
        </member>
        <member name="F:Google.Cloud.Vision.V1.AnnotateImageResponse.ImagePropertiesAnnotationFieldNumber">
            <summary>Field number for the "image_properties_annotation" field.</summary>
        </member>
        <member name="P:Google.Cloud.Vision.V1.AnnotateImageResponse.ImagePropertiesAnnotation">
            <summary>
            If present, image properties were extracted successfully.
            </summary>
        </member>
        <member name="F:Google.Cloud.Vision.V1.AnnotateImageResponse.CropHintsAnnotationFieldNumber">
            <summary>Field number for the "crop_hints_annotation" field.</summary>
        </member>
        <member name="P:Google.Cloud.Vision.V1.AnnotateImageResponse.CropHintsAnnotation">
            <summary>
            If present, crop hints have completed successfully.
            </summary>
        </member>
        <member name="F:Google.Cloud.Vision.V1.AnnotateImageResponse.WebDetectionFieldNumber">
            <summary>Field number for the "web_detection" field.</summary>
        </member>
        <member name="P:Google.Cloud.Vision.V1.AnnotateImageResponse.WebDetection">
            <summary>
            If present, web detection has completed successfully.
            </summary>
        </member>
        <member name="F:Google.Cloud.Vision.V1.AnnotateImageResponse.ErrorFieldNumber">
            <summary>Field number for the "error" field.</summary>
        </member>
        <member name="P:Google.Cloud.Vision.V1.AnnotateImageResponse.Error">
            <summary>
            If set, represents the error message for the operation.
            Note that filled-in image annotations are guaranteed to be
            correct, even when `error` is set.
            </summary>
        </member>
        <member name="T:Google.Cloud.Vision.V1.BatchAnnotateImagesResponse">
            <summary>
            Response to a batch image annotation request.
            </summary>
        </member>
        <member name="M:Google.Cloud.Vision.V1.BatchAnnotateImagesResponse.ThrowOnAnyError">
            <summary>
            If the <see cref="P:Google.Cloud.Vision.V1.AnnotateImageResponse.Error"/> property is non-null for any response within <see cref="P:Google.Cloud.Vision.V1.BatchAnnotateImagesResponse.Responses"/>,
            throws an <see cref="T:System.AggregateException"/>, containing one <see cref="T:Google.Cloud.Vision.V1.AnnotateImageException"/>
            for each failed response. Otherwise, returns <c>this</c> (so that the method can be called in a fluent manner).
            </summary>
            <exception cref="T:System.AggregateException">The <see cref="P:Google.Cloud.Vision.V1.AnnotateImageResponse.Error"/> property is non-null on one or
            more element of <see cref="P:Google.Cloud.Vision.V1.BatchAnnotateImagesResponse.Responses"/>.</exception>
            <returns><c>this</c> if no responses contain errors.</returns>
        </member>
        <member name="F:Google.Cloud.Vision.V1.BatchAnnotateImagesResponse.ResponsesFieldNumber">
            <summary>Field number for the "responses" field.</summary>
        </member>
        <member name="P:Google.Cloud.Vision.V1.BatchAnnotateImagesResponse.Responses">
            <summary>
            Individual responses to image annotation requests within the batch.
            </summary>
        </member>
        <member name="T:Google.Cloud.Vision.V1.GeometryReflection">
            <summary>Holder for reflection information generated from google/cloud/vision/v1/geometry.proto</summary>
        </member>
        <member name="P:Google.Cloud.Vision.V1.GeometryReflection.Descriptor">
            <summary>File descriptor for google/cloud/vision/v1/geometry.proto</summary>
        </member>
        <member name="T:Google.Cloud.Vision.V1.Vertex">
            <summary>
            A vertex represents a 2D point in the image.
            NOTE: the vertex coordinates are in the same scale as the original image.
            </summary>
        </member>
        <member name="F:Google.Cloud.Vision.V1.Vertex.XFieldNumber">
            <summary>Field number for the "x" field.</summary>
        </member>
        <member name="P:Google.Cloud.Vision.V1.Vertex.X">
            <summary>
            X coordinate.
            </summary>
        </member>
        <member name="F:Google.Cloud.Vision.V1.Vertex.YFieldNumber">
            <summary>Field number for the "y" field.</summary>
        </member>
        <member name="P:Google.Cloud.Vision.V1.Vertex.Y">
            <summary>
            Y coordinate.
            </summary>
        </member>
        <member name="T:Google.Cloud.Vision.V1.BoundingPoly">
            <summary>
            A bounding polygon for the detected image annotation.
            </summary>
        </member>
        <member name="F:Google.Cloud.Vision.V1.BoundingPoly.VerticesFieldNumber">
            <summary>Field number for the "vertices" field.</summary>
        </member>
        <member name="P:Google.Cloud.Vision.V1.BoundingPoly.Vertices">
            <summary>
            The bounding polygon vertices.
            </summary>
        </member>
        <member name="T:Google.Cloud.Vision.V1.Position">
            <summary>
            A 3D position in the image, used primarily for Face detection landmarks.
            A valid Position must have both x and y coordinates.
            The position coordinates are in the same scale as the original image.
            </summary>
        </member>
        <member name="F:Google.Cloud.Vision.V1.Position.XFieldNumber">
            <summary>Field number for the "x" field.</summary>
        </member>
        <member name="P:Google.Cloud.Vision.V1.Position.X">
            <summary>
            X coordinate.
            </summary>
        </member>
        <member name="F:Google.Cloud.Vision.V1.Position.YFieldNumber">
            <summary>Field number for the "y" field.</summary>
        </member>
        <member name="P:Google.Cloud.Vision.V1.Position.Y">
            <summary>
            Y coordinate.
            </summary>
        </member>
        <member name="F:Google.Cloud.Vision.V1.Position.ZFieldNumber">
            <summary>Field number for the "z" field.</summary>
        </member>
        <member name="P:Google.Cloud.Vision.V1.Position.Z">
            <summary>
            Z coordinate (or depth).
            </summary>
        </member>
        <member name="T:Google.Cloud.Vision.V1.ImageAnnotatorReflection">
            <summary>Holder for reflection information generated from google/cloud/vision/v1/image_annotator.proto</summary>
        </member>
        <member name="P:Google.Cloud.Vision.V1.ImageAnnotatorReflection.Descriptor">
            <summary>File descriptor for google/cloud/vision/v1/image_annotator.proto</summary>
        </member>
        <member name="T:Google.Cloud.Vision.V1.Likelihood">
            <summary>
            A bucketized representation of likelihood, which is intended to give clients
            highly stable results across model upgrades.
            </summary>
        </member>
        <member name="F:Google.Cloud.Vision.V1.Likelihood.Unknown">
            <summary>
            Unknown likelihood.
            </summary>
        </member>
        <member name="F:Google.Cloud.Vision.V1.Likelihood.VeryUnlikely">
            <summary>
            It is very unlikely that the image belongs to the specified vertical.
            </summary>
        </member>
        <member name="F:Google.Cloud.Vision.V1.Likelihood.Unlikely">
            <summary>
            It is unlikely that the image belongs to the specified vertical.
            </summary>
        </member>
        <member name="F:Google.Cloud.Vision.V1.Likelihood.Possible">
            <summary>
            It is possible that the image belongs to the specified vertical.
            </summary>
        </member>
        <member name="F:Google.Cloud.Vision.V1.Likelihood.Likely">
            <summary>
            It is likely that the image belongs to the specified vertical.
            </summary>
        </member>
        <member name="F:Google.Cloud.Vision.V1.Likelihood.VeryLikely">
            <summary>
            It is very likely that the image belongs to the specified vertical.
            </summary>
        </member>
        <member name="T:Google.Cloud.Vision.V1.Feature">
            <summary>
            The type of Google Cloud Vision API detection to perform, and the maximum
            number of results to return for that type. Multiple `Feature` objects can
            be specified in the `features` list.
            </summary>
        </member>
        <member name="F:Google.Cloud.Vision.V1.Feature.TypeFieldNumber">
            <summary>Field number for the "type" field.</summary>
        </member>
        <member name="P:Google.Cloud.Vision.V1.Feature.Type">
            <summary>
            The feature type.
            </summary>
        </member>
        <member name="F:Google.Cloud.Vision.V1.Feature.MaxResultsFieldNumber">
            <summary>Field number for the "max_results" field.</summary>
        </member>
        <member name="P:Google.Cloud.Vision.V1.Feature.MaxResults">
            <summary>
            Maximum number of results of this type. Does not apply to
            `TEXT_DETECTION`, `DOCUMENT_TEXT_DETECTION`, or `CROP_HINTS`.
            </summary>
        </member>
        <member name="F:Google.Cloud.Vision.V1.Feature.ModelFieldNumber">
            <summary>Field number for the "model" field.</summary>
        </member>
        <member name="P:Google.Cloud.Vision.V1.Feature.Model">
            <summary>
            Model to use for the feature.
            Supported values: "builtin/stable" (the default if unset) and
            "builtin/latest".
            </summary>
        </member>
        <member name="T:Google.Cloud.Vision.V1.Feature.Types">
            <summary>Container for nested types declared in the Feature message type.</summary>
        </member>
        <member name="T:Google.Cloud.Vision.V1.Feature.Types.Type">
            <summary>
            Type of Google Cloud Vision API feature to be extracted.
            </summary>
        </member>
        <member name="F:Google.Cloud.Vision.V1.Feature.Types.Type.Unspecified">
            <summary>
            Unspecified feature type.
            </summary>
        </member>
        <member name="F:Google.Cloud.Vision.V1.Feature.Types.Type.FaceDetection">
            <summary>
            Run face detection.
            </summary>
        </member>
        <member name="F:Google.Cloud.Vision.V1.Feature.Types.Type.LandmarkDetection">
            <summary>
            Run landmark detection.
            </summary>
        </member>
        <member name="F:Google.Cloud.Vision.V1.Feature.Types.Type.LogoDetection">
            <summary>
            Run logo detection.
            </summary>
        </member>
        <member name="F:Google.Cloud.Vision.V1.Feature.Types.Type.LabelDetection">
            <summary>
            Run label detection.
            </summary>
        </member>
        <member name="F:Google.Cloud.Vision.V1.Feature.Types.Type.TextDetection">
            <summary>
            Run text detection / optical character recognition (OCR). Text detection
            is optimized for areas of text within a larger image; if the image is
            a document, use `DOCUMENT_TEXT_DETECTION` instead.
            </summary>
        </member>
        <member name="F:Google.Cloud.Vision.V1.Feature.Types.Type.DocumentTextDetection">
            <summary>
            Run dense text document OCR. Takes precedence when both
            `DOCUMENT_TEXT_DETECTION` and `TEXT_DETECTION` are present.
            </summary>
        </member>
        <member name="F:Google.Cloud.Vision.V1.Feature.Types.Type.SafeSearchDetection">
            <summary>
            Run Safe Search to detect potentially unsafe
            or undesirable content.
            </summary>
        </member>
        <member name="F:Google.Cloud.Vision.V1.Feature.Types.Type.ImageProperties">
            <summary>
            Compute a set of image properties, such as the
            image's dominant colors.
            </summary>
        </member>
        <member name="F:Google.Cloud.Vision.V1.Feature.Types.Type.CropHints">
            <summary>
            Run crop hints.
            </summary>
        </member>
        <member name="F:Google.Cloud.Vision.V1.Feature.Types.Type.WebDetection">
            <summary>
            Run web detection.
            </summary>
        </member>
        <member name="T:Google.Cloud.Vision.V1.ImageSource">
            <summary>
            External image source (Google Cloud Storage or web URL image location).
            </summary>
        </member>
        <member name="F:Google.Cloud.Vision.V1.ImageSource.GcsImageUriFieldNumber">
            <summary>Field number for the "gcs_image_uri" field.</summary>
        </member>
        <member name="P:Google.Cloud.Vision.V1.ImageSource.GcsImageUri">
             <summary>
             **Use `image_uri` instead.**
            
             The Google Cloud Storage  URI of the form
             `gs://bucket_name/object_name`. Object versioning is not supported. See
             [Google Cloud Storage Request
             URIs](https://cloud.google.com/storage/docs/reference-uris) for more info.
             </summary>
        </member>
        <member name="F:Google.Cloud.Vision.V1.ImageSource.ImageUriFieldNumber">
            <summary>Field number for the "image_uri" field.</summary>
        </member>
        <member name="P:Google.Cloud.Vision.V1.ImageSource.ImageUri">
             <summary>
             The URI of the source image. Can be either:
            
             1. A Google Cloud Storage URI of the form
                `gs://bucket_name/object_name`. Object versioning is not supported. See
                [Google Cloud Storage Request
                URIs](https://cloud.google.com/storage/docs/reference-uris) for more
                info.
            
             2. A publicly-accessible image HTTP/HTTPS URL. When fetching images from
                HTTP/HTTPS URLs, Google cannot guarantee that the request will be
                completed. Your request may fail if the specified host denies the
                request (e.g. due to request throttling or DOS prevention), or if Google
                throttles requests to the site for abuse prevention. You should not
                depend on externally-hosted images for production applications.
            
             When both `gcs_image_uri` and `image_uri` are specified, `image_uri` takes
             precedence.
             </summary>
        </member>
        <member name="T:Google.Cloud.Vision.V1.Image">
            <summary>
            Client image to perform Google Cloud Vision API tasks over.
            </summary>
        </member>
        <member name="F:Google.Cloud.Vision.V1.Image.ContentFieldNumber">
            <summary>Field number for the "content" field.</summary>
        </member>
        <member name="P:Google.Cloud.Vision.V1.Image.Content">
            <summary>
            Image content, represented as a stream of bytes.
            Note: As with all `bytes` fields, protobuffers use a pure binary
            representation, whereas JSON representations use base64.
            </summary>
        </member>
        <member name="F:Google.Cloud.Vision.V1.Image.SourceFieldNumber">
            <summary>Field number for the "source" field.</summary>
        </member>
        <member name="P:Google.Cloud.Vision.V1.Image.Source">
            <summary>
            Google Cloud Storage image location, or publicly-accessible image
            URL. If both `content` and `source` are provided for an image, `content`
            takes precedence and is used to perform the image annotation request.
            </summary>
        </member>
        <member name="M:Google.Cloud.Vision.V1.Image.FromUri(System.String)">
            <summary>
            Constructs an <see cref="T:Google.Cloud.Vision.V1.Image"/> with a <see cref="P:Google.Cloud.Vision.V1.Image.Source"/> property referring to a URI,
            which may either be a Google Cloud Storage URI or a publicly accessible HTTP or HTTPS URI. The
            image is fetched from the URI by the Google Cloud Vision server.
            </summary>
            <param name="uri">The URI of the image, which may either be a Google Cloud Storage URI of the form <c>gs://bucket-name/file-name</c>
            or a publicly accessibly HTTP or HTTPS URI. Must not be null.</param>
            <returns>The newly created image.</returns>
        </member>
        <member name="M:Google.Cloud.Vision.V1.Image.FromUri(System.Uri)">
            <summary>
            Constructs an <see cref="T:Google.Cloud.Vision.V1.Image"/> with a <see cref="P:Google.Cloud.Vision.V1.Image.Source"/> property referring to a URI,
            which may either be a Google Cloud Storage URI or a publicly accessible HTTP or HTTPS URI. The
            image is fetched from the URI by the Google Cloud Vision server.
            </summary>
            <param name="uri">The URI of the image, which may either be a Google Cloud Storage URI of the form <c>gs://bucket-name/file-name</c>
            or a publicly accessibly HTTP or HTTPS URI. Must not be null.</param>
            <returns>The newly created image.</returns>
        </member>
        <member name="M:Google.Cloud.Vision.V1.Image.FetchFromUriAsync(System.Uri,System.Net.Http.HttpClient)">
            <summary>
            Asynchronously constructs an <see cref="T:Google.Cloud.Vision.V1.Image"/> by downloading data from the given URI.
            </summary>
            <remarks>
            <para>Unlike <see cref="M:Google.Cloud.Vision.V1.Image.FromUri(System.Uri)"/>, this method downloads the image locally then uploads
            it to the Google Cloud Vision server.</para>
            </remarks>
            <param name="uri">The URI to fetch. Must not be null.</param>
            <param name="httpClient">The <see cref="T:System.Net.Http.HttpClient"/> to use to fetch the image, or
            <c>null</c> to use a default client.</param>
            <returns>A task representing the asynchronous operation. The result will be the newly created image.</returns>
        </member>
        <member name="M:Google.Cloud.Vision.V1.Image.FetchFromUriAsync(System.String,System.Net.Http.HttpClient)">
            <summary>
            Asynchronously constructs an <see cref="T:Google.Cloud.Vision.V1.Image"/> by downloading data from the given URI.
            </summary>
            <remarks>
            <para>Unlike <see cref="M:Google.Cloud.Vision.V1.Image.FromUri(System.Uri)"/>, this method downloads the image locally then uploads
            it to the Google Cloud Vision server.</para>
            </remarks>
            <param name="uri">The URI to fetch. Must not be null.</param>
            <param name="httpClient">The <see cref="T:System.Net.Http.HttpClient"/> to use to fetch the image, or
            <c>null</c> to use a default client.</param>
            <returns>A task representing the asynchronous operation. The result will be the newly created image.</returns>
        </member>
        <member name="M:Google.Cloud.Vision.V1.Image.FetchFromUri(System.String,System.Net.Http.HttpClient)">
            <summary>
            Constructs an <see cref="T:Google.Cloud.Vision.V1.Image"/> by downloading data from the given URI.
            </summary>
            <remarks>
            <para>Unlike <see cref="M:Google.Cloud.Vision.V1.Image.FromUri(System.String)"/>, this method downloads the image locally then uploads
            it to the Google Cloud Vision server.</para>
            </remarks>
            <param name="uri">The URI to fetch. Must not be null.</param>
            <param name="httpClient">The <see cref="T:System.Net.Http.HttpClient"/> to use to fetch the image, or
            <c>null</c> to use a default client.</param>
            <returns>The newly created image.</returns>
        </member>
        <member name="M:Google.Cloud.Vision.V1.Image.FetchFromUri(System.Uri,System.Net.Http.HttpClient)">
            <summary>
            Constructs an <see cref="T:Google.Cloud.Vision.V1.Image"/> by downloading data from the given URI.
            </summary>
            <remarks>
            <para>Unlike <see cref="M:Google.Cloud.Vision.V1.Image.FromUri(System.String)"/>, this method downloads the image locally then uploads
            it to the Google Cloud Vision server.</para>
            </remarks>
            <param name="uri">The URI to fetch. Must not be null.</param>
            <param name="httpClient">The <see cref="T:System.Net.Http.HttpClient"/> to use to fetch the image, or
            <c>null</c> to use a default client.</param>
            <returns>The newly created image.</returns>
        </member>
        <member name="M:Google.Cloud.Vision.V1.Image.FromFile(System.String)">
            <summary>
            Constructs an <see cref="T:Google.Cloud.Vision.V1.Image"/> by loading data from the given file path.
            </summary>
            <param name="path">The file path to load image data from. Must not be null.</param>
            <returns>The newly created image.</returns>
        </member>
        <member name="M:Google.Cloud.Vision.V1.Image.FromFileAsync(System.String)">
            <summary>
            Asynchronously constructs an <see cref="T:Google.Cloud.Vision.V1.Image"/> by loading data from the given file path.
            </summary>
            <param name="path">The file path to load image data from. Must not be null.</param>
            <returns>The newly created image.</returns>
        </member>
        <member name="M:Google.Cloud.Vision.V1.Image.FromStream(System.IO.Stream)">
            <summary>
            Constructs an <see cref="T:Google.Cloud.Vision.V1.Image"/> by loading data from the given stream.
            </summary>
            <param name="stream">The stream to load image data from. Must not be null.</param>
            <returns>The newly created image.</returns>
        </member>
        <member name="M:Google.Cloud.Vision.V1.Image.FromStreamAsync(System.IO.Stream)">
            <summary>
            Asynchronously constructs an <see cref="T:Google.Cloud.Vision.V1.Image"/> by loading data from the given stream.
            </summary>
            <param name="stream">The stream to load image data from. Must not be null.</param>
            <returns>The newly created image.</returns>
        </member>
        <member name="M:Google.Cloud.Vision.V1.Image.FromBytes(System.Byte[])">
            <summary>
            Constructs an <see cref="T:Google.Cloud.Vision.V1.Image"/> from the given byte array.
            </summary>
            <remarks>This method copies the data from the byte array; modifications to <paramref name="bytes"/>
            after this method returns will not be reflected in the image.</remarks>
            <param name="bytes">The bytes representing the raw image data.</param>
            <returns>The newly created image.</returns>
        </member>
        <member name="M:Google.Cloud.Vision.V1.Image.FromBytes(System.Byte[],System.Int32,System.Int32)">
            <summary>
            Constructs an <see cref="T:Google.Cloud.Vision.V1.Image"/> from a section of the given byte array.
            </summary>
            <remarks>This method copies the data from the byte array; modifications to <paramref name="bytes"/>
            after this method returns will not be reflected in the image.</remarks>
            <param name="bytes">The bytes representing the raw image data.</param>
            <param name="offset">The offset into the byte array of the start of the data to include in the image.</param>
            <param name="count">The number of bytes to include in the image.</param>
            <returns>The newly created image.</returns>
        </member>
        <member name="T:Google.Cloud.Vision.V1.FaceAnnotation">
            <summary>
            A face annotation object contains the results of face detection.
            </summary>
        </member>
        <member name="F:Google.Cloud.Vision.V1.FaceAnnotation.BoundingPolyFieldNumber">
            <summary>Field number for the "bounding_poly" field.</summary>
        </member>
        <member name="P:Google.Cloud.Vision.V1.FaceAnnotation.BoundingPoly">
            <summary>
            The bounding polygon around the face. The coordinates of the bounding box
            are in the original image's scale, as returned in `ImageParams`.
            The bounding box is computed to "frame" the face in accordance with human
            expectations. It is based on the landmarker results.
            Note that one or more x and/or y coordinates may not be generated in the
            `BoundingPoly` (the polygon will be unbounded) if only a partial face
            appears in the image to be annotated.
            </summary>
        </member>
        <member name="F:Google.Cloud.Vision.V1.FaceAnnotation.FdBoundingPolyFieldNumber">
            <summary>Field number for the "fd_bounding_poly" field.</summary>
        </member>
        <member name="P:Google.Cloud.Vision.V1.FaceAnnotation.FdBoundingPoly">
            <summary>
            The `fd_bounding_poly` bounding polygon is tighter than the
            `boundingPoly`, and encloses only the skin part of the face. Typically, it
            is used to eliminate the face from any image analysis that detects the
            "amount of skin" visible in an image. It is not based on the
            landmarker results, only on the initial face detection, hence
            the &lt;code>fd&lt;/code> (face detection) prefix.
            </summary>
        </member>
        <member name="F:Google.Cloud.Vision.V1.FaceAnnotation.LandmarksFieldNumber">
            <summary>Field number for the "landmarks" field.</summary>
        </member>
        <member name="P:Google.Cloud.Vision.V1.FaceAnnotation.Landmarks">
            <summary>
            Detected face landmarks.
            </summary>
        </member>
        <member name="F:Google.Cloud.Vision.V1.FaceAnnotation.RollAngleFieldNumber">
            <summary>Field number for the "roll_angle" field.</summary>
        </member>
        <member name="P:Google.Cloud.Vision.V1.FaceAnnotation.RollAngle">
            <summary>
            Roll angle, which indicates the amount of clockwise/anti-clockwise rotation
            of the face relative to the image vertical about the axis perpendicular to
            the face. Range [-180,180].
            </summary>
        </member>
        <member name="F:Google.Cloud.Vision.V1.FaceAnnotation.PanAngleFieldNumber">
            <summary>Field number for the "pan_angle" field.</summary>
        </member>
        <member name="P:Google.Cloud.Vision.V1.FaceAnnotation.PanAngle">
            <summary>
            Yaw angle, which indicates the leftward/rightward angle that the face is
            pointing relative to the vertical plane perpendicular to the image. Range
            [-180,180].
            </summary>
        </member>
        <member name="F:Google.Cloud.Vision.V1.FaceAnnotation.TiltAngleFieldNumber">
            <summary>Field number for the "tilt_angle" field.</summary>
        </member>
        <member name="P:Google.Cloud.Vision.V1.FaceAnnotation.TiltAngle">
            <summary>
            Pitch angle, which indicates the upwards/downwards angle that the face is
            pointing relative to the image's horizontal plane. Range [-180,180].
            </summary>
        </member>
        <member name="F:Google.Cloud.Vision.V1.FaceAnnotation.DetectionConfidenceFieldNumber">
            <summary>Field number for the "detection_confidence" field.</summary>
        </member>
        <member name="P:Google.Cloud.Vision.V1.FaceAnnotation.DetectionConfidence">
            <summary>
            Detection confidence. Range [0, 1].
            </summary>
        </member>
        <member name="F:Google.Cloud.Vision.V1.FaceAnnotation.LandmarkingConfidenceFieldNumber">
            <summary>Field number for the "landmarking_confidence" field.</summary>
        </member>
        <member name="P:Google.Cloud.Vision.V1.FaceAnnotation.LandmarkingConfidence">
            <summary>
            Face landmarking confidence. Range [0, 1].
            </summary>
        </member>
        <member name="F:Google.Cloud.Vision.V1.FaceAnnotation.JoyLikelihoodFieldNumber">
            <summary>Field number for the "joy_likelihood" field.</summary>
        </member>
        <member name="P:Google.Cloud.Vision.V1.FaceAnnotation.JoyLikelihood">
            <summary>
            Joy likelihood.
            </summary>
        </member>
        <member name="F:Google.Cloud.Vision.V1.FaceAnnotation.SorrowLikelihoodFieldNumber">
            <summary>Field number for the "sorrow_likelihood" field.</summary>
        </member>
        <member name="P:Google.Cloud.Vision.V1.FaceAnnotation.SorrowLikelihood">
            <summary>
            Sorrow likelihood.
            </summary>
        </member>
        <member name="F:Google.Cloud.Vision.V1.FaceAnnotation.AngerLikelihoodFieldNumber">
            <summary>Field number for the "anger_likelihood" field.</summary>
        </member>
        <member name="P:Google.Cloud.Vision.V1.FaceAnnotation.AngerLikelihood">
            <summary>
            Anger likelihood.
            </summary>
        </member>
        <member name="F:Google.Cloud.Vision.V1.FaceAnnotation.SurpriseLikelihoodFieldNumber">
            <summary>Field number for the "surprise_likelihood" field.</summary>
        </member>
        <member name="P:Google.Cloud.Vision.V1.FaceAnnotation.SurpriseLikelihood">
            <summary>
            Surprise likelihood.
            </summary>
        </member>
        <member name="F:Google.Cloud.Vision.V1.FaceAnnotation.UnderExposedLikelihoodFieldNumber">
            <summary>Field number for the "under_exposed_likelihood" field.</summary>
        </member>
        <member name="P:Google.Cloud.Vision.V1.FaceAnnotation.UnderExposedLikelihood">
            <summary>
            Under-exposed likelihood.
            </summary>
        </member>
        <member name="F:Google.Cloud.Vision.V1.FaceAnnotation.BlurredLikelihoodFieldNumber">
            <summary>Field number for the "blurred_likelihood" field.</summary>
        </member>
        <member name="P:Google.Cloud.Vision.V1.FaceAnnotation.BlurredLikelihood">
            <summary>
            Blurred likelihood.
            </summary>
        </member>
        <member name="F:Google.Cloud.Vision.V1.FaceAnnotation.HeadwearLikelihoodFieldNumber">
            <summary>Field number for the "headwear_likelihood" field.</summary>
        </member>
        <member name="P:Google.Cloud.Vision.V1.FaceAnnotation.HeadwearLikelihood">
            <summary>
            Headwear likelihood.
            </summary>
        </member>
        <member name="T:Google.Cloud.Vision.V1.FaceAnnotation.Types">
            <summary>Container for nested types declared in the FaceAnnotation message type.</summary>
        </member>
        <member name="T:Google.Cloud.Vision.V1.FaceAnnotation.Types.Landmark">
            <summary>
            A face-specific landmark (for example, a face feature).
            </summary>
        </member>
        <member name="F:Google.Cloud.Vision.V1.FaceAnnotation.Types.Landmark.TypeFieldNumber">
            <summary>Field number for the "type" field.</summary>
        </member>
        <member name="P:Google.Cloud.Vision.V1.FaceAnnotation.Types.Landmark.Type">
            <summary>
            Face landmark type.
            </summary>
        </member>
        <member name="F:Google.Cloud.Vision.V1.FaceAnnotation.Types.Landmark.PositionFieldNumber">
            <summary>Field number for the "position" field.</summary>
        </member>
        <member name="P:Google.Cloud.Vision.V1.FaceAnnotation.Types.Landmark.Position">
            <summary>
            Face landmark position.
            </summary>
        </member>
        <member name="T:Google.Cloud.Vision.V1.FaceAnnotation.Types.Landmark.Types">
            <summary>Container for nested types declared in the Landmark message type.</summary>
        </member>
        <member name="T:Google.Cloud.Vision.V1.FaceAnnotation.Types.Landmark.Types.Type">
            <summary>
            Face landmark (feature) type.
            Left and right are defined from the vantage of the viewer of the image
            without considering mirror projections typical of photos. So, `LEFT_EYE`,
            typically, is the person's right eye.
            </summary>
        </member>
        <member name="F:Google.Cloud.Vision.V1.FaceAnnotation.Types.Landmark.Types.Type.UnknownLandmark">
            <summary>
            Unknown face landmark detected. Should not be filled.
            </summary>
        </member>
        <member name="F:Google.Cloud.Vision.V1.FaceAnnotation.Types.Landmark.Types.Type.LeftEye">
            <summary>
            Left eye.
            </summary>
        </member>
        <member name="F:Google.Cloud.Vision.V1.FaceAnnotation.Types.Landmark.Types.Type.RightEye">
            <summary>
            Right eye.
            </summary>
        </member>
        <member name="F:Google.Cloud.Vision.V1.FaceAnnotation.Types.Landmark.Types.Type.LeftOfLeftEyebrow">
            <summary>
            Left of left eyebrow.
            </summary>
        </member>
        <member name="F:Google.Cloud.Vision.V1.FaceAnnotation.Types.Landmark.Types.Type.RightOfLeftEyebrow">
            <summary>
            Right of left eyebrow.
            </summary>
        </member>
        <member name="F:Google.Cloud.Vision.V1.FaceAnnotation.Types.Landmark.Types.Type.LeftOfRightEyebrow">
            <summary>
            Left of right eyebrow.
            </summary>
        </member>
        <member name="F:Google.Cloud.Vision.V1.FaceAnnotation.Types.Landmark.Types.Type.RightOfRightEyebrow">
            <summary>
            Right of right eyebrow.
            </summary>
        </member>
        <member name="F:Google.Cloud.Vision.V1.FaceAnnotation.Types.Landmark.Types.Type.MidpointBetweenEyes">
            <summary>
            Midpoint between eyes.
            </summary>
        </member>
        <member name="F:Google.Cloud.Vision.V1.FaceAnnotation.Types.Landmark.Types.Type.NoseTip">
            <summary>
            Nose tip.
            </summary>
        </member>
        <member name="F:Google.Cloud.Vision.V1.FaceAnnotation.Types.Landmark.Types.Type.UpperLip">
            <summary>
            Upper lip.
            </summary>
        </member>
        <member name="F:Google.Cloud.Vision.V1.FaceAnnotation.Types.Landmark.Types.Type.LowerLip">
            <summary>
            Lower lip.
            </summary>
        </member>
        <member name="F:Google.Cloud.Vision.V1.FaceAnnotation.Types.Landmark.Types.Type.MouthLeft">
            <summary>
            Mouth left.
            </summary>
        </member>
        <member name="F:Google.Cloud.Vision.V1.FaceAnnotation.Types.Landmark.Types.Type.MouthRight">
            <summary>
            Mouth right.
            </summary>
        </member>
        <member name="F:Google.Cloud.Vision.V1.FaceAnnotation.Types.Landmark.Types.Type.MouthCenter">
            <summary>
            Mouth center.
            </summary>
        </member>
        <member name="F:Google.Cloud.Vision.V1.FaceAnnotation.Types.Landmark.Types.Type.NoseBottomRight">
            <summary>
            Nose, bottom right.
            </summary>
        </member>
        <member name="F:Google.Cloud.Vision.V1.FaceAnnotation.Types.Landmark.Types.Type.NoseBottomLeft">
            <summary>
            Nose, bottom left.
            </summary>
        </member>
        <member name="F:Google.Cloud.Vision.V1.FaceAnnotation.Types.Landmark.Types.Type.NoseBottomCenter">
            <summary>
            Nose, bottom center.
            </summary>
        </member>
        <member name="F:Google.Cloud.Vision.V1.FaceAnnotation.Types.Landmark.Types.Type.LeftEyeTopBoundary">
            <summary>
            Left eye, top boundary.
            </summary>
        </member>
        <member name="F:Google.Cloud.Vision.V1.FaceAnnotation.Types.Landmark.Types.Type.LeftEyeRightCorner">
            <summary>
            Left eye, right corner.
            </summary>
        </member>
        <member name="F:Google.Cloud.Vision.V1.FaceAnnotation.Types.Landmark.Types.Type.LeftEyeBottomBoundary">
            <summary>
            Left eye, bottom boundary.
            </summary>
        </member>
        <member name="F:Google.Cloud.Vision.V1.FaceAnnotation.Types.Landmark.Types.Type.LeftEyeLeftCorner">
            <summary>
            Left eye, left corner.
            </summary>
        </member>
        <member name="F:Google.Cloud.Vision.V1.FaceAnnotation.Types.Landmark.Types.Type.RightEyeTopBoundary">
            <summary>
            Right eye, top boundary.
            </summary>
        </member>
        <member name="F:Google.Cloud.Vision.V1.FaceAnnotation.Types.Landmark.Types.Type.RightEyeRightCorner">
            <summary>
            Right eye, right corner.
            </summary>
        </member>
        <member name="F:Google.Cloud.Vision.V1.FaceAnnotation.Types.Landmark.Types.Type.RightEyeBottomBoundary">
            <summary>
            Right eye, bottom boundary.
            </summary>
        </member>
        <member name="F:Google.Cloud.Vision.V1.FaceAnnotation.Types.Landmark.Types.Type.RightEyeLeftCorner">
            <summary>
            Right eye, left corner.
            </summary>
        </member>
        <member name="F:Google.Cloud.Vision.V1.FaceAnnotation.Types.Landmark.Types.Type.LeftEyebrowUpperMidpoint">
            <summary>
            Left eyebrow, upper midpoint.
            </summary>
        </member>
        <member name="F:Google.Cloud.Vision.V1.FaceAnnotation.Types.Landmark.Types.Type.RightEyebrowUpperMidpoint">
            <summary>
            Right eyebrow, upper midpoint.
            </summary>
        </member>
        <member name="F:Google.Cloud.Vision.V1.FaceAnnotation.Types.Landmark.Types.Type.LeftEarTragion">
            <summary>
            Left ear tragion.
            </summary>
        </member>
        <member name="F:Google.Cloud.Vision.V1.FaceAnnotation.Types.Landmark.Types.Type.RightEarTragion">
            <summary>
            Right ear tragion.
            </summary>
        </member>
        <member name="F:Google.Cloud.Vision.V1.FaceAnnotation.Types.Landmark.Types.Type.LeftEyePupil">
            <summary>
            Left eye pupil.
            </summary>
        </member>
        <member name="F:Google.Cloud.Vision.V1.FaceAnnotation.Types.Landmark.Types.Type.RightEyePupil">
            <summary>
            Right eye pupil.
            </summary>
        </member>
        <member name="F:Google.Cloud.Vision.V1.FaceAnnotation.Types.Landmark.Types.Type.ForeheadGlabella">
            <summary>
            Forehead glabella.
            </summary>
        </member>
        <member name="F:Google.Cloud.Vision.V1.FaceAnnotation.Types.Landmark.Types.Type.ChinGnathion">
            <summary>
            Chin gnathion.
            </summary>
        </member>
        <member name="F:Google.Cloud.Vision.V1.FaceAnnotation.Types.Landmark.Types.Type.ChinLeftGonion">
            <summary>
            Chin left gonion.
            </summary>
        </member>
        <member name="F:Google.Cloud.Vision.V1.FaceAnnotation.Types.Landmark.Types.Type.ChinRightGonion">
            <summary>
            Chin right gonion.
            </summary>
        </member>
        <member name="T:Google.Cloud.Vision.V1.LocationInfo">
            <summary>
            Detected entity location information.
            </summary>
        </member>
        <member name="F:Google.Cloud.Vision.V1.LocationInfo.LatLngFieldNumber">
            <summary>Field number for the "lat_lng" field.</summary>
        </member>
        <member name="P:Google.Cloud.Vision.V1.LocationInfo.LatLng">
            <summary>
            lat/long location coordinates.
            </summary>
        </member>
        <member name="T:Google.Cloud.Vision.V1.Property">
            <summary>
            A `Property` consists of a user-supplied name/value pair.
            </summary>
        </member>
        <member name="F:Google.Cloud.Vision.V1.Property.NameFieldNumber">
            <summary>Field number for the "name" field.</summary>
        </member>
        <member name="P:Google.Cloud.Vision.V1.Property.Name">
            <summary>
            Name of the property.
            </summary>
        </member>
        <member name="F:Google.Cloud.Vision.V1.Property.ValueFieldNumber">
            <summary>Field number for the "value" field.</summary>
        </member>
        <member name="P:Google.Cloud.Vision.V1.Property.Value">
            <summary>
            Value of the property.
            </summary>
        </member>
        <member name="F:Google.Cloud.Vision.V1.Property.Uint64ValueFieldNumber">
            <summary>Field number for the "uint64_value" field.</summary>
        </member>
        <member name="P:Google.Cloud.Vision.V1.Property.Uint64Value">
            <summary>
            Value of numeric properties.
            </summary>
        </member>
        <member name="T:Google.Cloud.Vision.V1.EntityAnnotation">
            <summary>
            Set of detected entity features.
            </summary>
        </member>
        <member name="F:Google.Cloud.Vision.V1.EntityAnnotation.MidFieldNumber">
            <summary>Field number for the "mid" field.</summary>
        </member>
        <member name="P:Google.Cloud.Vision.V1.EntityAnnotation.Mid">
            <summary>
            Opaque entity ID. Some IDs may be available in
            [Google Knowledge Graph Search
            API](https://developers.google.com/knowledge-graph/).
            </summary>
        </member>
        <member name="F:Google.Cloud.Vision.V1.EntityAnnotation.LocaleFieldNumber">
            <summary>Field number for the "locale" field.</summary>
        </member>
        <member name="P:Google.Cloud.Vision.V1.EntityAnnotation.Locale">
            <summary>
            The language code for the locale in which the entity textual
            `description` is expressed.
            </summary>
        </member>
        <member name="F:Google.Cloud.Vision.V1.EntityAnnotation.DescriptionFieldNumber">
            <summary>Field number for the "description" field.</summary>
        </member>
        <member name="P:Google.Cloud.Vision.V1.EntityAnnotation.Description">
            <summary>
            Entity textual description, expressed in its `locale` language.
            </summary>
        </member>
        <member name="F:Google.Cloud.Vision.V1.EntityAnnotation.ScoreFieldNumber">
            <summary>Field number for the "score" field.</summary>
        </member>
        <member name="P:Google.Cloud.Vision.V1.EntityAnnotation.Score">
            <summary>
            Overall score of the result. Range [0, 1].
            </summary>
        </member>
        <member name="F:Google.Cloud.Vision.V1.EntityAnnotation.ConfidenceFieldNumber">
            <summary>Field number for the "confidence" field.</summary>
        </member>
        <member name="P:Google.Cloud.Vision.V1.EntityAnnotation.Confidence">
            <summary>
            **Deprecated. Use `score` instead.**
            The accuracy of the entity detection in an image.
            For example, for an image in which the "Eiffel Tower" entity is detected,
            this field represents the confidence that there is a tower in the query
            image. Range [0, 1].
            </summary>
        </member>
        <member name="F:Google.Cloud.Vision.V1.EntityAnnotation.TopicalityFieldNumber">
            <summary>Field number for the "topicality" field.</summary>
        </member>
        <member name="P:Google.Cloud.Vision.V1.EntityAnnotation.Topicality">
            <summary>
            The relevancy of the ICA (Image Content Annotation) label to the
            image. For example, the relevancy of "tower" is likely higher to an image
            containing the detected "Eiffel Tower" than to an image containing a
            detected distant towering building, even though the confidence that
            there is a tower in each image may be the same. Range [0, 1].
            </summary>
        </member>
        <member name="F:Google.Cloud.Vision.V1.EntityAnnotation.BoundingPolyFieldNumber">
            <summary>Field number for the "bounding_poly" field.</summary>
        </member>
        <member name="P:Google.Cloud.Vision.V1.EntityAnnotation.BoundingPoly">
            <summary>
            Image region to which this entity belongs. Not produced
            for `LABEL_DETECTION` features.
            </summary>
        </member>
        <member name="F:Google.Cloud.Vision.V1.EntityAnnotation.LocationsFieldNumber">
            <summary>Field number for the "locations" field.</summary>
        </member>
        <member name="P:Google.Cloud.Vision.V1.EntityAnnotation.Locations">
            <summary>
            The location information for the detected entity. Multiple
            `LocationInfo` elements can be present because one location may
            indicate the location of the scene in the image, and another location
            may indicate the location of the place where the image was taken.
            Location information is usually present for landmarks.
            </summary>
        </member>
        <member name="F:Google.Cloud.Vision.V1.EntityAnnotation.PropertiesFieldNumber">
            <summary>Field number for the "properties" field.</summary>
        </member>
        <member name="P:Google.Cloud.Vision.V1.EntityAnnotation.Properties">
            <summary>
            Some entities may have optional user-supplied `Property` (name/value)
            fields, such a score or string that qualifies the entity.
            </summary>
        </member>
        <member name="T:Google.Cloud.Vision.V1.SafeSearchAnnotation">
            <summary>
            Set of features pertaining to the image, computed by computer vision
            methods over safe-search verticals (for example, adult, spoof, medical,
            violence).
            </summary>
        </member>
        <member name="F:Google.Cloud.Vision.V1.SafeSearchAnnotation.AdultFieldNumber">
            <summary>Field number for the "adult" field.</summary>
        </member>
        <member name="P:Google.Cloud.Vision.V1.SafeSearchAnnotation.Adult">
            <summary>
            Represents the adult content likelihood for the image. Adult content may
            contain elements such as nudity, pornographic images or cartoons, or
            sexual activities.
            </summary>
        </member>
        <member name="F:Google.Cloud.Vision.V1.SafeSearchAnnotation.SpoofFieldNumber">
            <summary>Field number for the "spoof" field.</summary>
        </member>
        <member name="P:Google.Cloud.Vision.V1.SafeSearchAnnotation.Spoof">
            <summary>
            Spoof likelihood. The likelihood that an modification
            was made to the image's canonical version to make it appear
            funny or offensive.
            </summary>
        </member>
        <member name="F:Google.Cloud.Vision.V1.SafeSearchAnnotation.MedicalFieldNumber">
            <summary>Field number for the "medical" field.</summary>
        </member>
        <member name="P:Google.Cloud.Vision.V1.SafeSearchAnnotation.Medical">
            <summary>
            Likelihood that this is a medical image.
            </summary>
        </member>
        <member name="F:Google.Cloud.Vision.V1.SafeSearchAnnotation.ViolenceFieldNumber">
            <summary>Field number for the "violence" field.</summary>
        </member>
        <member name="P:Google.Cloud.Vision.V1.SafeSearchAnnotation.Violence">
            <summary>
            Likelihood that this image contains violent content.
            </summary>
        </member>
        <member name="F:Google.Cloud.Vision.V1.SafeSearchAnnotation.RacyFieldNumber">
            <summary>Field number for the "racy" field.</summary>
        </member>
        <member name="P:Google.Cloud.Vision.V1.SafeSearchAnnotation.Racy">
            <summary>
            Likelihood that the request image contains racy content. Racy content may
            include (but is not limited to) skimpy or sheer clothing, strategically
            covered nudity, lewd or provocative poses, or close-ups of sensitive
            body areas.
            </summary>
        </member>
        <member name="T:Google.Cloud.Vision.V1.LatLongRect">
            <summary>
            Rectangle determined by min and max `LatLng` pairs.
            </summary>
        </member>
        <member name="F:Google.Cloud.Vision.V1.LatLongRect.MinLatLngFieldNumber">
            <summary>Field number for the "min_lat_lng" field.</summary>
        </member>
        <member name="P:Google.Cloud.Vision.V1.LatLongRect.MinLatLng">
            <summary>
            Min lat/long pair.
            </summary>
        </member>
        <member name="F:Google.Cloud.Vision.V1.LatLongRect.MaxLatLngFieldNumber">
            <summary>Field number for the "max_lat_lng" field.</summary>
        </member>
        <member name="P:Google.Cloud.Vision.V1.LatLongRect.MaxLatLng">
            <summary>
            Max lat/long pair.
            </summary>
        </member>
        <member name="T:Google.Cloud.Vision.V1.ColorInfo">
            <summary>
            Color information consists of RGB channels, score, and the fraction of
            the image that the color occupies in the image.
            </summary>
        </member>
        <member name="F:Google.Cloud.Vision.V1.ColorInfo.ColorFieldNumber">
            <summary>Field number for the "color" field.</summary>
        </member>
        <member name="P:Google.Cloud.Vision.V1.ColorInfo.Color">
            <summary>
            RGB components of the color.
            </summary>
        </member>
        <member name="F:Google.Cloud.Vision.V1.ColorInfo.ScoreFieldNumber">
            <summary>Field number for the "score" field.</summary>
        </member>
        <member name="P:Google.Cloud.Vision.V1.ColorInfo.Score">
            <summary>
            Image-specific score for this color. Value in range [0, 1].
            </summary>
        </member>
        <member name="F:Google.Cloud.Vision.V1.ColorInfo.PixelFractionFieldNumber">
            <summary>Field number for the "pixel_fraction" field.</summary>
        </member>
        <member name="P:Google.Cloud.Vision.V1.ColorInfo.PixelFraction">
            <summary>
            The fraction of pixels the color occupies in the image.
            Value in range [0, 1].
            </summary>
        </member>
        <member name="T:Google.Cloud.Vision.V1.DominantColorsAnnotation">
            <summary>
            Set of dominant colors and their corresponding scores.
            </summary>
        </member>
        <member name="F:Google.Cloud.Vision.V1.DominantColorsAnnotation.ColorsFieldNumber">
            <summary>Field number for the "colors" field.</summary>
        </member>
        <member name="P:Google.Cloud.Vision.V1.DominantColorsAnnotation.Colors">
            <summary>
            RGB color values with their score and pixel fraction.
            </summary>
        </member>
        <member name="T:Google.Cloud.Vision.V1.ImageProperties">
            <summary>
            Stores image properties, such as dominant colors.
            </summary>
        </member>
        <member name="F:Google.Cloud.Vision.V1.ImageProperties.DominantColorsFieldNumber">
            <summary>Field number for the "dominant_colors" field.</summary>
        </member>
        <member name="P:Google.Cloud.Vision.V1.ImageProperties.DominantColors">
            <summary>
            If present, dominant colors completed successfully.
            </summary>
        </member>
        <member name="T:Google.Cloud.Vision.V1.CropHint">
            <summary>
            Single crop hint that is used to generate a new crop when serving an image.
            </summary>
        </member>
        <member name="F:Google.Cloud.Vision.V1.CropHint.BoundingPolyFieldNumber">
            <summary>Field number for the "bounding_poly" field.</summary>
        </member>
        <member name="P:Google.Cloud.Vision.V1.CropHint.BoundingPoly">
            <summary>
            The bounding polygon for the crop region. The coordinates of the bounding
            box are in the original image's scale, as returned in `ImageParams`.
            </summary>
        </member>
        <member name="F:Google.Cloud.Vision.V1.CropHint.ConfidenceFieldNumber">
            <summary>Field number for the "confidence" field.</summary>
        </member>
        <member name="P:Google.Cloud.Vision.V1.CropHint.Confidence">
            <summary>
            Confidence of this being a salient region.  Range [0, 1].
            </summary>
        </member>
        <member name="F:Google.Cloud.Vision.V1.CropHint.ImportanceFractionFieldNumber">
            <summary>Field number for the "importance_fraction" field.</summary>
        </member>
        <member name="P:Google.Cloud.Vision.V1.CropHint.ImportanceFraction">
            <summary>
            Fraction of importance of this salient region with respect to the original
            image.
            </summary>
        </member>
        <member name="T:Google.Cloud.Vision.V1.CropHintsAnnotation">
            <summary>
            Set of crop hints that are used to generate new crops when serving images.
            </summary>
        </member>
        <member name="F:Google.Cloud.Vision.V1.CropHintsAnnotation.CropHintsFieldNumber">
            <summary>Field number for the "crop_hints" field.</summary>
        </member>
        <member name="P:Google.Cloud.Vision.V1.CropHintsAnnotation.CropHints">
            <summary>
            Crop hint results.
            </summary>
        </member>
        <member name="T:Google.Cloud.Vision.V1.CropHintsParams">
            <summary>
            Parameters for crop hints annotation request.
            </summary>
        </member>
        <member name="F:Google.Cloud.Vision.V1.CropHintsParams.AspectRatiosFieldNumber">
            <summary>Field number for the "aspect_ratios" field.</summary>
        </member>
        <member name="P:Google.Cloud.Vision.V1.CropHintsParams.AspectRatios">
            <summary>
            Aspect ratios in floats, representing the ratio of the width to the height
            of the image. For example, if the desired aspect ratio is 4/3, the
            corresponding float value should be 1.33333.  If not specified, the
            best possible crop is returned. The number of provided aspect ratios is
            limited to a maximum of 16; any aspect ratios provided after the 16th are
            ignored.
            </summary>
        </member>
        <member name="T:Google.Cloud.Vision.V1.WebDetectionParams">
            <summary>
            Parameters for web detection request.
            </summary>
        </member>
        <member name="F:Google.Cloud.Vision.V1.WebDetectionParams.IncludeGeoResultsFieldNumber">
            <summary>Field number for the "include_geo_results" field.</summary>
        </member>
        <member name="P:Google.Cloud.Vision.V1.WebDetectionParams.IncludeGeoResults">
            <summary>
            Whether to include results derived from the geo information in the image.
            </summary>
        </member>
        <member name="T:Google.Cloud.Vision.V1.ImageContext">
            <summary>
            Image context and/or feature-specific parameters.
            </summary>
        </member>
        <member name="F:Google.Cloud.Vision.V1.ImageContext.LatLongRectFieldNumber">
            <summary>Field number for the "lat_long_rect" field.</summary>
        </member>
        <member name="P:Google.Cloud.Vision.V1.ImageContext.LatLongRect">
            <summary>
            lat/long rectangle that specifies the location of the image.
            </summary>
        </member>
        <member name="F:Google.Cloud.Vision.V1.ImageContext.LanguageHintsFieldNumber">
            <summary>Field number for the "language_hints" field.</summary>
        </member>
        <member name="P:Google.Cloud.Vision.V1.ImageContext.LanguageHints">
            <summary>
            List of languages to use for TEXT_DETECTION. In most cases, an empty value
            yields the best results since it enables automatic language detection. For
            languages based on the Latin alphabet, setting `language_hints` is not
            needed. In rare cases, when the language of the text in the image is known,
            setting a hint will help get better results (although it will be a
            significant hindrance if the hint is wrong). Text detection returns an
            error if one or more of the specified languages is not one of the
            [supported languages](/vision/docs/languages).
            </summary>
        </member>
        <member name="F:Google.Cloud.Vision.V1.ImageContext.CropHintsParamsFieldNumber">
            <summary>Field number for the "crop_hints_params" field.</summary>
        </member>
        <member name="P:Google.Cloud.Vision.V1.ImageContext.CropHintsParams">
            <summary>
            Parameters for crop hints annotation request.
            </summary>
        </member>
        <member name="F:Google.Cloud.Vision.V1.ImageContext.WebDetectionParamsFieldNumber">
            <summary>Field number for the "web_detection_params" field.</summary>
        </member>
        <member name="P:Google.Cloud.Vision.V1.ImageContext.WebDetectionParams">
            <summary>
            Parameters for web detection.
            </summary>
        </member>
        <member name="T:Google.Cloud.Vision.V1.AnnotateImageRequest">
            <summary>
            Request for performing Google Cloud Vision API tasks over a user-provided
            image, with user-requested features.
            </summary>
        </member>
        <member name="F:Google.Cloud.Vision.V1.AnnotateImageRequest.ImageFieldNumber">
            <summary>Field number for the "image" field.</summary>
        </member>
        <member name="P:Google.Cloud.Vision.V1.AnnotateImageRequest.Image">
            <summary>
            The image to be processed.
            </summary>
        </member>
        <member name="F:Google.Cloud.Vision.V1.AnnotateImageRequest.FeaturesFieldNumber">
            <summary>Field number for the "features" field.</summary>
        </member>
        <member name="P:Google.Cloud.Vision.V1.AnnotateImageRequest.Features">
            <summary>
            Requested features.
            </summary>
        </member>
        <member name="F:Google.Cloud.Vision.V1.AnnotateImageRequest.ImageContextFieldNumber">
            <summary>Field number for the "image_context" field.</summary>
        </member>
        <member name="P:Google.Cloud.Vision.V1.AnnotateImageRequest.ImageContext">
            <summary>
            Additional context that may accompany the image.
            </summary>
        </member>
        <member name="T:Google.Cloud.Vision.V1.BatchAnnotateImagesRequest">
            <summary>
            Multiple image annotation requests are batched into a single service call.
            </summary>
        </member>
        <member name="F:Google.Cloud.Vision.V1.BatchAnnotateImagesRequest.RequestsFieldNumber">
            <summary>Field number for the "requests" field.</summary>
        </member>
        <member name="P:Google.Cloud.Vision.V1.BatchAnnotateImagesRequest.Requests">
            <summary>
            Individual image annotation requests for this batch.
            </summary>
        </member>
        <member name="T:Google.Cloud.Vision.V1.ImageAnnotatorSettings">
            <summary>
            Settings for a <see cref="T:Google.Cloud.Vision.V1.ImageAnnotatorClient"/>.
            </summary>
        </member>
        <member name="M:Google.Cloud.Vision.V1.ImageAnnotatorSettings.GetDefault">
            <summary>
            Get a new instance of the default <see cref="T:Google.Cloud.Vision.V1.ImageAnnotatorSettings"/>.
            </summary>
            <returns>
            A new instance of the default <see cref="T:Google.Cloud.Vision.V1.ImageAnnotatorSettings"/>.
            </returns>
        </member>
        <member name="M:Google.Cloud.Vision.V1.ImageAnnotatorSettings.#ctor">
            <summary>
            Constructs a new <see cref="T:Google.Cloud.Vision.V1.ImageAnnotatorSettings"/> object with default settings.
            </summary>
        </member>
        <member name="P:Google.Cloud.Vision.V1.ImageAnnotatorSettings.IdempotentRetryFilter">
            <summary>
            The filter specifying which RPC <see cref="T:Grpc.Core.StatusCode"/>s are eligible for retry
            for "Idempotent" <see cref="T:Google.Cloud.Vision.V1.ImageAnnotatorClient"/> RPC methods.
            </summary>
            <remarks>
            The eligible RPC <see cref="T:Grpc.Core.StatusCode"/>s for retry for "Idempotent" RPC methods are:
            <list type="bullet">
            <item><description><see cref="F:Grpc.Core.StatusCode.DeadlineExceeded"/></description></item>
            <item><description><see cref="F:Grpc.Core.StatusCode.Unavailable"/></description></item>
            </list>
            </remarks>
        </member>
        <member name="P:Google.Cloud.Vision.V1.ImageAnnotatorSettings.NonIdempotentRetryFilter">
            <summary>
            The filter specifying which RPC <see cref="T:Grpc.Core.StatusCode"/>s are eligible for retry
            for "NonIdempotent" <see cref="T:Google.Cloud.Vision.V1.ImageAnnotatorClient"/> RPC methods.
            </summary>
            <remarks>
            There are no RPC <see cref="T:Grpc.Core.StatusCode"/>s eligible for retry for "NonIdempotent" RPC methods.
            </remarks>
        </member>
        <member name="M:Google.Cloud.Vision.V1.ImageAnnotatorSettings.GetDefaultRetryBackoff">
            <summary>
            "Default" retry backoff for <see cref="T:Google.Cloud.Vision.V1.ImageAnnotatorClient"/> RPC methods.
            </summary>
            <returns>
            The "Default" retry backoff for <see cref="T:Google.Cloud.Vision.V1.ImageAnnotatorClient"/> RPC methods.
            </returns>
            <remarks>
            The "Default" retry backoff for <see cref="T:Google.Cloud.Vision.V1.ImageAnnotatorClient"/> RPC methods is defined as:
            <list type="bullet">
            <item><description>Initial delay: 100 milliseconds</description></item>
            <item><description>Maximum delay: 60000 milliseconds</description></item>
            <item><description>Delay multiplier: 1.3</description></item>
            </list>
            </remarks>
        </member>
        <member name="M:Google.Cloud.Vision.V1.ImageAnnotatorSettings.GetDefaultTimeoutBackoff">
            <summary>
            "Default" timeout backoff for <see cref="T:Google.Cloud.Vision.V1.ImageAnnotatorClient"/> RPC methods.
            </summary>
            <returns>
            The "Default" timeout backoff for <see cref="T:Google.Cloud.Vision.V1.ImageAnnotatorClient"/> RPC methods.
            </returns>
            <remarks>
            The "Default" timeout backoff for <see cref="T:Google.Cloud.Vision.V1.ImageAnnotatorClient"/> RPC methods is defined as:
            <list type="bullet">
            <item><description>Initial timeout: 60000 milliseconds</description></item>
            <item><description>Timeout multiplier: 1.0</description></item>
            <item><description>Maximum timeout: 60000 milliseconds</description></item>
            </list>
            </remarks>
        </member>
        <member name="P:Google.Cloud.Vision.V1.ImageAnnotatorSettings.BatchAnnotateImagesSettings">
            <summary>
            <see cref="T:Google.Api.Gax.Grpc.CallSettings"/> for synchronous and asynchronous calls to
            <c>ImageAnnotatorClient.BatchAnnotateImages</c> and <c>ImageAnnotatorClient.BatchAnnotateImagesAsync</c>.
            </summary>
            <remarks>
            The default <c>ImageAnnotatorClient.BatchAnnotateImages</c> and
            <c>ImageAnnotatorClient.BatchAnnotateImagesAsync</c> <see cref="T:Google.Api.Gax.Grpc.RetrySettings"/> are:
            <list type="bullet">
            <item><description>Initial retry delay: 100 milliseconds</description></item>
            <item><description>Retry delay multiplier: 1.3</description></item>
            <item><description>Retry maximum delay: 60000 milliseconds</description></item>
            <item><description>Initial timeout: 60000 milliseconds</description></item>
            <item><description>Timeout multiplier: 1.0</description></item>
            <item><description>Timeout maximum delay: 60000 milliseconds</description></item>
            </list>
            Retry will be attempted on the following response status codes:
            <list>
            <item><description><see cref="F:Grpc.Core.StatusCode.DeadlineExceeded"/></description></item>
            <item><description><see cref="F:Grpc.Core.StatusCode.Unavailable"/></description></item>
            </list>
            Default RPC expiration is 600000 milliseconds.
            </remarks>
        </member>
        <member name="M:Google.Cloud.Vision.V1.ImageAnnotatorSettings.Clone">
            <summary>
            Creates a deep clone of this object, with all the same property values.
            </summary>
            <returns>A deep clone of this <see cref="T:Google.Cloud.Vision.V1.ImageAnnotatorSettings"/> object.</returns>
        </member>
        <member name="T:Google.Cloud.Vision.V1.ImageAnnotatorClient">
            <summary>
            ImageAnnotator client wrapper, for convenient use.
            </summary>
        </member>
        <member name="P:Google.Cloud.Vision.V1.ImageAnnotatorClient.DefaultEndpoint">
            <summary>
            The default endpoint for the ImageAnnotator service, which is a host of "vision.googleapis.com" and a port of 443.
            </summary>
        </member>
        <member name="P:Google.Cloud.Vision.V1.ImageAnnotatorClient.DefaultScopes">
            <summary>
            The default ImageAnnotator scopes.
            </summary>
            <remarks>
            The default ImageAnnotator scopes are:
            <list type="bullet">
            <item><description>"https://www.googleapis.com/auth/cloud-platform"</description></item>
            <item><description>"https://www.googleapis.com/auth/cloud-vision"</description></item>
            </list>
            </remarks>
        </member>
        <member name="M:Google.Cloud.Vision.V1.ImageAnnotatorClient.CreateAsync(Google.Api.Gax.Grpc.ServiceEndpoint,Google.Cloud.Vision.V1.ImageAnnotatorSettings)">
            <summary>
            Asynchronously creates a <see cref="T:Google.Cloud.Vision.V1.ImageAnnotatorClient"/>, applying defaults for all unspecified settings,
            and creating a channel connecting to the given endpoint with application default credentials where
            necessary.
            </summary>
            <param name="endpoint">Optional <see cref="T:Google.Api.Gax.Grpc.ServiceEndpoint"/>.</param>
            <param name="settings">Optional <see cref="T:Google.Cloud.Vision.V1.ImageAnnotatorSettings"/>.</param>
            <returns>The task representing the created <see cref="T:Google.Cloud.Vision.V1.ImageAnnotatorClient"/>.</returns>
        </member>
        <member name="M:Google.Cloud.Vision.V1.ImageAnnotatorClient.Create(Google.Api.Gax.Grpc.ServiceEndpoint,Google.Cloud.Vision.V1.ImageAnnotatorSettings)">
            <summary>
            Synchronously creates a <see cref="T:Google.Cloud.Vision.V1.ImageAnnotatorClient"/>, applying defaults for all unspecified settings,
            and creating a channel connecting to the given endpoint with application default credentials where
            necessary.
            </summary>
            <param name="endpoint">Optional <see cref="T:Google.Api.Gax.Grpc.ServiceEndpoint"/>.</param>
            <param name="settings">Optional <see cref="T:Google.Cloud.Vision.V1.ImageAnnotatorSettings"/>.</param>
            <returns>The created <see cref="T:Google.Cloud.Vision.V1.ImageAnnotatorClient"/>.</returns>
        </member>
        <member name="M:Google.Cloud.Vision.V1.ImageAnnotatorClient.Create(Grpc.Core.Channel,Google.Cloud.Vision.V1.ImageAnnotatorSettings)">
            <summary>
            Creates a <see cref="T:Google.Cloud.Vision.V1.ImageAnnotatorClient"/> which uses the specified channel for remote operations.
            </summary>
            <param name="channel">The <see cref="T:Grpc.Core.Channel"/> for remote operations. Must not be null.</param>
            <param name="settings">Optional <see cref="T:Google.Cloud.Vision.V1.ImageAnnotatorSettings"/>.</param>
            <returns>The created <see cref="T:Google.Cloud.Vision.V1.ImageAnnotatorClient"/>.</returns>
        </member>
        <member name="M:Google.Cloud.Vision.V1.ImageAnnotatorClient.ShutdownDefaultChannelsAsync">
            <summary>
            Shuts down any channels automatically created by <see cref="M:Google.Cloud.Vision.V1.ImageAnnotatorClient.Create(Google.Api.Gax.Grpc.ServiceEndpoint,Google.Cloud.Vision.V1.ImageAnnotatorSettings)"/>
            and <see cref="M:Google.Cloud.Vision.V1.ImageAnnotatorClient.CreateAsync(Google.Api.Gax.Grpc.ServiceEndpoint,Google.Cloud.Vision.V1.ImageAnnotatorSettings)"/>. Channels which weren't automatically
            created are not affected.
            </summary>
            <remarks>After calling this method, further calls to <see cref="M:Google.Cloud.Vision.V1.ImageAnnotatorClient.Create(Google.Api.Gax.Grpc.ServiceEndpoint,Google.Cloud.Vision.V1.ImageAnnotatorSettings)"/>
            and <see cref="M:Google.Cloud.Vision.V1.ImageAnnotatorClient.CreateAsync(Google.Api.Gax.Grpc.ServiceEndpoint,Google.Cloud.Vision.V1.ImageAnnotatorSettings)"/> will create new channels, which could
            in turn be shut down by another call to this method.</remarks>
            <returns>A task representing the asynchronous shutdown operation.</returns>
        </member>
        <member name="P:Google.Cloud.Vision.V1.ImageAnnotatorClient.GrpcClient">
            <summary>
            The underlying gRPC ImageAnnotator client.
            </summary>
        </member>
        <member name="M:Google.Cloud.Vision.V1.ImageAnnotatorClient.BatchAnnotateImagesAsync(System.Collections.Generic.IEnumerable{Google.Cloud.Vision.V1.AnnotateImageRequest},Google.Api.Gax.Grpc.CallSettings)">
            <summary>
            Run image detection and annotation for a batch of images.
            </summary>
            <param name="requests">
            Individual image annotation requests for this batch.
            </param>
            <param name="callSettings">
            If not null, applies overrides to this RPC call.
            </param>
            <returns>
            A Task containing the RPC response.
            </returns>
        </member>
        <member name="M:Google.Cloud.Vision.V1.ImageAnnotatorClient.BatchAnnotateImagesAsync(System.Collections.Generic.IEnumerable{Google.Cloud.Vision.V1.AnnotateImageRequest},System.Threading.CancellationToken)">
            <summary>
            Run image detection and annotation for a batch of images.
            </summary>
            <param name="requests">
            Individual image annotation requests for this batch.
            </param>
            <param name="cancellationToken">
            A <see cref="T:System.Threading.CancellationToken"/> to use for this RPC.
            </param>
            <returns>
            A Task containing the RPC response.
            </returns>
        </member>
        <member name="M:Google.Cloud.Vision.V1.ImageAnnotatorClient.BatchAnnotateImages(System.Collections.Generic.IEnumerable{Google.Cloud.Vision.V1.AnnotateImageRequest},Google.Api.Gax.Grpc.CallSettings)">
            <summary>
            Run image detection and annotation for a batch of images.
            </summary>
            <param name="requests">
            Individual image annotation requests for this batch.
            </param>
            <param name="callSettings">
            If not null, applies overrides to this RPC call.
            </param>
            <returns>
            The RPC response.
            </returns>
        </member>
        <member name="M:Google.Cloud.Vision.V1.ImageAnnotatorClient.BatchAnnotateImagesAsync(Google.Cloud.Vision.V1.BatchAnnotateImagesRequest,Google.Api.Gax.Grpc.CallSettings)">
            <summary>
            Run image detection and annotation for a batch of images.
            </summary>
            <param name="request">
            The request object containing all of the parameters for the API call.
            </param>
            <param name="callSettings">
            If not null, applies overrides to this RPC call.
            </param>
            <returns>
            A Task containing the RPC response.
            </returns>
        </member>
        <member name="M:Google.Cloud.Vision.V1.ImageAnnotatorClient.BatchAnnotateImages(Google.Cloud.Vision.V1.BatchAnnotateImagesRequest,Google.Api.Gax.Grpc.CallSettings)">
            <summary>
            Run image detection and annotation for a batch of images.
            </summary>
            <param name="request">
            The request object containing all of the parameters for the API call.
            </param>
            <param name="callSettings">
            If not null, applies overrides to this RPC call.
            </param>
            <returns>
            The RPC response.
            </returns>
        </member>
        <member name="M:Google.Cloud.Vision.V1.ImageAnnotatorClient.DetectFaces(Google.Cloud.Vision.V1.Image,Google.Cloud.Vision.V1.ImageContext,System.Int32,Google.Api.Gax.Grpc.CallSettings)">
            <summary>
            Detects the faces in a single image.
            </summary>
            <remarks>
            If <see cref="T:Google.Cloud.Vision.V1.AnnotateImageException"/> is thrown, the original response can still be retrieved using
            <see cref="P:Google.Cloud.Vision.V1.AnnotateImageException.Response"/>.
            </remarks>
            <param name="image">The image to process. Must not be null.</param>
            <param name="context">Additional contextual information, if any.</param>
            <param name="maxResults">The maximum number of results to return. 0 (the default) means "unlimited". Must not be negative.</param>
            <param name="callSettings">Call settings to apply to the RPC, if any.</param>
            <exception cref="T:Google.Cloud.Vision.V1.AnnotateImageException">The RPC returns a response, but the response contains an error.</exception>
            <returns>A set of annotations.</returns>
        </member>
        <member name="M:Google.Cloud.Vision.V1.ImageAnnotatorClient.DetectFacesAsync(Google.Cloud.Vision.V1.Image,Google.Cloud.Vision.V1.ImageContext,System.Int32,Google.Api.Gax.Grpc.CallSettings)">
            <summary>
            Detects the faces in a single image asynchronously.
            </summary>
            <remarks>
            If <see cref="T:Google.Cloud.Vision.V1.AnnotateImageException"/> is thrown, the original response can still be retrieved using
            <see cref="P:Google.Cloud.Vision.V1.AnnotateImageException.Response"/>.
            </remarks>
            <param name="image">The image to process. Must not be null.</param>
            <param name="context">Additional contextual information, if any.</param>
            <param name="maxResults">The maximum number of results to return. 0 (the default) means "unlimited". Must not be negative.</param>
            <param name="callSettings">Call settings to apply to the RPC, if any.</param>
            <exception cref="T:Google.Cloud.Vision.V1.AnnotateImageException">The RPC returns a response, but the response contains an error.</exception>
            <returns>A task representing the asynchronous operation. The task result will be a set of annotations.</returns>
        </member>
        <member name="M:Google.Cloud.Vision.V1.ImageAnnotatorClient.DetectLabels(Google.Cloud.Vision.V1.Image,Google.Cloud.Vision.V1.ImageContext,System.Int32,Google.Api.Gax.Grpc.CallSettings)">
            <summary>
            Detects labels for a single image.
            </summary>
            <remarks>
            If <see cref="T:Google.Cloud.Vision.V1.AnnotateImageException"/> is thrown, the original response can still be retrieved using
            <see cref="P:Google.Cloud.Vision.V1.AnnotateImageException.Response"/>.
            </remarks>
            <param name="image">The image to process. Must not be null.</param>
            <param name="context">Additional contextual information, if any.</param>
            <param name="maxResults">The maximum number of results to return. 0 (the default) means "unlimited". Must not be negative.</param>
            <param name="callSettings">Call settings to apply to the RPC, if any.</param>
            <exception cref="T:Google.Cloud.Vision.V1.AnnotateImageException">The RPC returns a response, but the response contains an error.</exception>
            <returns>A set of annotations.</returns>
        </member>
        <member name="M:Google.Cloud.Vision.V1.ImageAnnotatorClient.DetectLabelsAsync(Google.Cloud.Vision.V1.Image,Google.Cloud.Vision.V1.ImageContext,System.Int32,Google.Api.Gax.Grpc.CallSettings)">
            <summary>
            Detects labels for a single image asynchronously.
            </summary>
            <remarks>
            If <see cref="T:Google.Cloud.Vision.V1.AnnotateImageException"/> is thrown, the original response can still be retrieved using
            <see cref="P:Google.Cloud.Vision.V1.AnnotateImageException.Response"/>.
            </remarks>
            <param name="image">The image to process. Must not be null.</param>
            <param name="context">Additional contextual information, if any.</param>
            <param name="maxResults">The maximum number of results to return. 0 (the default) means "unlimited". Must not be negative.</param>
            <param name="callSettings">Call settings to apply to the RPC, if any.</param>
            <exception cref="T:Google.Cloud.Vision.V1.AnnotateImageException">The RPC returns a response, but the response contains an error.</exception>
            <returns>A task representing the asynchronous operation. The task result will be a set of annotations.</returns>
        </member>
        <member name="M:Google.Cloud.Vision.V1.ImageAnnotatorClient.DetectLandmarks(Google.Cloud.Vision.V1.Image,Google.Cloud.Vision.V1.ImageContext,System.Int32,Google.Api.Gax.Grpc.CallSettings)">
            <summary>
            Detects landmarks in a single image.
            </summary>
            <remarks>
            If <see cref="T:Google.Cloud.Vision.V1.AnnotateImageException"/> is thrown, the original response can still be retrieved using
            <see cref="P:Google.Cloud.Vision.V1.AnnotateImageException.Response"/>.
            </remarks>
            <param name="image">The image to process. Must not be null.</param>
            <param name="context">Additional contextual information, if any.</param>
            <param name="maxResults">The maximum number of results to return. 0 (the default) means "unlimited". Must not be negative.</param>
            <param name="callSettings">Call settings to apply to the RPC, if any.</param>
            <exception cref="T:Google.Cloud.Vision.V1.AnnotateImageException">The RPC returns a response, but the response contains an error.</exception>
            <returns>A set of annotations.</returns>
        </member>
        <member name="M:Google.Cloud.Vision.V1.ImageAnnotatorClient.DetectLandmarksAsync(Google.Cloud.Vision.V1.Image,Google.Cloud.Vision.V1.ImageContext,System.Int32,Google.Api.Gax.Grpc.CallSettings)">
            <summary>
            Detects the landmarks in a single image asynchronously.
            </summary>
            <remarks>
            If <see cref="T:Google.Cloud.Vision.V1.AnnotateImageException"/> is thrown, the original response can still be retrieved using
            <see cref="P:Google.Cloud.Vision.V1.AnnotateImageException.Response"/>.
            </remarks>
            <param name="image">The image to process. Must not be null.</param>
            <param name="context">Additional contextual information, if any.</param>
            <param name="maxResults">The maximum number of results to return. 0 (the default) means "unlimited". Must not be negative.</param>
            <param name="callSettings">Call settings to apply to the RPC, if any.</param>
            <exception cref="T:Google.Cloud.Vision.V1.AnnotateImageException">The RPC returns a response, but the response contains an error.</exception>
            <returns>A task representing the asynchronous operation. The task result will be a set of annotations.</returns>
        </member>
        <member name="M:Google.Cloud.Vision.V1.ImageAnnotatorClient.DetectLogos(Google.Cloud.Vision.V1.Image,Google.Cloud.Vision.V1.ImageContext,System.Int32,Google.Api.Gax.Grpc.CallSettings)">
            <summary>
            Detects logos in a single image.
            </summary>
            <remarks>
            If <see cref="T:Google.Cloud.Vision.V1.AnnotateImageException"/> is thrown, the original response can still be retrieved using
            <see cref="P:Google.Cloud.Vision.V1.AnnotateImageException.Response"/>.
            </remarks>
            <param name="image">The image to process. Must not be null.</param>
            <param name="context">Additional contextual information, if any.</param>
            <param name="maxResults">The maximum number of results to return. 0 (the default) means "unlimited". Must not be negative.</param>
            <param name="callSettings">Call settings to apply to the RPC, if any.</param>
            <exception cref="T:Google.Cloud.Vision.V1.AnnotateImageException">The RPC returns a response, but the response contains an error.</exception>
            <returns>A set of annotations.</returns>
        </member>
        <member name="M:Google.Cloud.Vision.V1.ImageAnnotatorClient.DetectLogosAsync(Google.Cloud.Vision.V1.Image,Google.Cloud.Vision.V1.ImageContext,System.Int32,Google.Api.Gax.Grpc.CallSettings)">
            <summary>
            Detects logos in a single image asynchronously.
            </summary>
            <remarks>
            If <see cref="T:Google.Cloud.Vision.V1.AnnotateImageException"/> is thrown, the original response can still be retrieved using
            <see cref="P:Google.Cloud.Vision.V1.AnnotateImageException.Response"/>.
            </remarks>
            <param name="image">The image to process. Must not be null.</param>
            <param name="context">Additional contextual information, if any.</param>
            <param name="maxResults">The maximum number of results to return. 0 (the default) means "unlimited". Must not be negative.</param>
            <param name="callSettings">Call settings to apply to the RPC, if any.</param>
            <exception cref="T:Google.Cloud.Vision.V1.AnnotateImageException">The RPC returns a response, but the response contains an error.</exception>
            <returns>A task representing the asynchronous operation. The task result will be a set of annotations.</returns>
        </member>
        <member name="M:Google.Cloud.Vision.V1.ImageAnnotatorClient.DetectText(Google.Cloud.Vision.V1.Image,Google.Cloud.Vision.V1.ImageContext,System.Int32,Google.Api.Gax.Grpc.CallSettings)">
            <summary>
            Detects text in a single image.
            </summary>
            <remarks>
            <para>
            This method is suitable for an image with individual words; for more structured text,
            use <see cref="M:Google.Cloud.Vision.V1.ImageAnnotatorClient.DetectDocumentText(Google.Cloud.Vision.V1.Image,Google.Cloud.Vision.V1.ImageContext,Google.Api.Gax.Grpc.CallSettings)"/>.
            </para>
            <para>
            If <see cref="T:Google.Cloud.Vision.V1.AnnotateImageException"/> is thrown, the original response can still be retrieved using
            <see cref="P:Google.Cloud.Vision.V1.AnnotateImageException.Response"/>.
            </para>
            </remarks>
            <param name="image">The image to process. Must not be null.</param>
            <param name="context">Additional contextual information, if any.</param>
            <param name="maxResults">The maximum number of results to return. 0 (the default) means "unlimited". Must not be negative.</param>
            <param name="callSettings">Call settings to apply to the RPC, if any.</param>
            <exception cref="T:Google.Cloud.Vision.V1.AnnotateImageException">The RPC returns a response, but the response contains an error.</exception>
            <returns>A set of annotations.</returns>
        </member>
        <member name="M:Google.Cloud.Vision.V1.ImageAnnotatorClient.DetectTextAsync(Google.Cloud.Vision.V1.Image,Google.Cloud.Vision.V1.ImageContext,System.Int32,Google.Api.Gax.Grpc.CallSettings)">
            <summary>
            Detects text in a single image asynchronously.
            </summary>
            <remarks>
            <para>
            This method is suitable for an image with individual words; for more structured text,
            use <see cref="M:Google.Cloud.Vision.V1.ImageAnnotatorClient.DetectDocumentTextAsync(Google.Cloud.Vision.V1.Image,Google.Cloud.Vision.V1.ImageContext,Google.Api.Gax.Grpc.CallSettings)"/>.
            </para>
            <para>
            If <see cref="T:Google.Cloud.Vision.V1.AnnotateImageException"/> is thrown, the original response can still be retrieved using
            <see cref="P:Google.Cloud.Vision.V1.AnnotateImageException.Response"/>.
            </para>
            </remarks>
            <param name="image">The image to process. Must not be null.</param>
            <param name="context">Additional contextual information, if any.</param>
            <param name="maxResults">The maximum number of results to return. 0 (the default) means "unlimited". Must not be negative.</param>
            <param name="callSettings">Call settings to apply to the RPC, if any.</param>
            <exception cref="T:Google.Cloud.Vision.V1.AnnotateImageException">The RPC returns a response, but the response contains an error.</exception>
            <returns>A task representing the asynchronous operation. The task result will be a set of annotations.</returns>
        </member>
        <member name="M:Google.Cloud.Vision.V1.ImageAnnotatorClient.DetectDocumentText(Google.Cloud.Vision.V1.Image,Google.Cloud.Vision.V1.ImageContext,Google.Api.Gax.Grpc.CallSettings)">
            <summary>
            Detects document text in a single image.
            </summary>
            <remarks>
            If <see cref="T:Google.Cloud.Vision.V1.AnnotateImageException"/> is thrown, the original response can still be retrieved using
            <see cref="P:Google.Cloud.Vision.V1.AnnotateImageException.Response"/>.
            </remarks>
            <param name="image">The image to process. Must not be null.</param>
            <param name="context">Additional contextual information, if any.</param>
            <param name="callSettings">Call settings to apply to the RPC, if any.</param>
            <exception cref="T:Google.Cloud.Vision.V1.AnnotateImageException">The RPC returns a response, but the response contains an error.</exception>
            <returns>A task representing the asynchronous operation. The task result will be a set of annotations.</returns>
        </member>
        <member name="M:Google.Cloud.Vision.V1.ImageAnnotatorClient.DetectDocumentTextAsync(Google.Cloud.Vision.V1.Image,Google.Cloud.Vision.V1.ImageContext,Google.Api.Gax.Grpc.CallSettings)">
            <summary>
            Detects document text in a single image asynchronously.
            </summary>
            <remarks>
            If <see cref="T:Google.Cloud.Vision.V1.AnnotateImageException"/> is thrown, the original response can still be retrieved using
            <see cref="P:Google.Cloud.Vision.V1.AnnotateImageException.Response"/>.
            </remarks>
            <param name="image">The image to process. Must not be null.</param>
            <param name="context">Additional contextual information, if any.</param>
            <param name="callSettings">Call settings to apply to the RPC, if any.</param>
            <exception cref="T:Google.Cloud.Vision.V1.AnnotateImageException">The RPC returns a response, but the response contains an error.</exception>
            <returns>A task representing the asynchronous operation. The task result will be a set of annotations.</returns>
        </member>
        <member name="M:Google.Cloud.Vision.V1.ImageAnnotatorClient.DetectCropHints(Google.Cloud.Vision.V1.Image,Google.Cloud.Vision.V1.ImageContext,Google.Api.Gax.Grpc.CallSettings)">
            <summary>
            Suggests crop hints for a single image.
            </summary>
            <remarks>
            If <see cref="T:Google.Cloud.Vision.V1.AnnotateImageException"/> is thrown, the original response can still be retrieved using
            <see cref="P:Google.Cloud.Vision.V1.AnnotateImageException.Response"/>.
            </remarks>
            <param name="image">The image to process. Must not be null.</param>
            <param name="context">Additional contextual information, if any.</param>
            <param name="callSettings">Call settings to apply to the RPC, if any.</param>
            <exception cref="T:Google.Cloud.Vision.V1.AnnotateImageException">The RPC returns a response, but the response contains an error.</exception>
            <returns>A task representing the asynchronous operation. The task result will be a set of annotations.</returns>
        </member>
        <member name="M:Google.Cloud.Vision.V1.ImageAnnotatorClient.DetectCropHintsAsync(Google.Cloud.Vision.V1.Image,Google.Cloud.Vision.V1.ImageContext,Google.Api.Gax.Grpc.CallSettings)">
            <summary>
            Suggests crop hints for a single image asynchronously.
            </summary>
            <remarks>
            If <see cref="T:Google.Cloud.Vision.V1.AnnotateImageException"/> is thrown, the original response can still be retrieved using
            <see cref="P:Google.Cloud.Vision.V1.AnnotateImageException.Response"/>.
            </remarks>
            <param name="image">The image to process. Must not be null.</param>
            <param name="context">Additional contextual information, if any.</param>
            <param name="callSettings">Call settings to apply to the RPC, if any.</param>
            <exception cref="T:Google.Cloud.Vision.V1.AnnotateImageException">The RPC returns a response, but the response contains an error.</exception>
            <returns>A task representing the asynchronous operation. The task result will be a set of annotations.</returns>
        </member>
        <member name="M:Google.Cloud.Vision.V1.ImageAnnotatorClient.DetectWebInformation(Google.Cloud.Vision.V1.Image,Google.Cloud.Vision.V1.ImageContext,Google.Api.Gax.Grpc.CallSettings)">
            <summary>
            Performs web detection for a single image.
            </summary>
            <remarks>
            If <see cref="T:Google.Cloud.Vision.V1.AnnotateImageException"/> is thrown, the original response can still be retrieved using
            <see cref="P:Google.Cloud.Vision.V1.AnnotateImageException.Response"/>.
            </remarks>
            <param name="image">The image to process. Must not be null.</param>
            <param name="context">Additional contextual information, if any.</param>
            <param name="callSettings">Call settings to apply to the RPC, if any.</param>
            <exception cref="T:Google.Cloud.Vision.V1.AnnotateImageException">The RPC returns a response, but the response contains an error.</exception>
            <returns>A task representing the asynchronous operation. The task result will be a set of annotations.</returns>
        </member>
        <member name="M:Google.Cloud.Vision.V1.ImageAnnotatorClient.DetectWebInformationAsync(Google.Cloud.Vision.V1.Image,Google.Cloud.Vision.V1.ImageContext,Google.Api.Gax.Grpc.CallSettings)">
            <summary>
            Performs web detection for a single image asynchronously.
            </summary>
            <remarks>
            If <see cref="T:Google.Cloud.Vision.V1.AnnotateImageException"/> is thrown, the original response can still be retrieved using
            <see cref="P:Google.Cloud.Vision.V1.AnnotateImageException.Response"/>.
            </remarks>
            <param name="image">The image to process. Must not be null.</param>
            <param name="context">Additional contextual information, if any.</param>
            <param name="callSettings">Call settings to apply to the RPC, if any.</param>
            <exception cref="T:Google.Cloud.Vision.V1.AnnotateImageException">The RPC returns a response, but the response contains an error.</exception>
            <returns>A task representing the asynchronous operation. The task result will be a set of annotations.</returns>
        </member>
        <member name="M:Google.Cloud.Vision.V1.ImageAnnotatorClient.DetectSafeSearch(Google.Cloud.Vision.V1.Image,Google.Cloud.Vision.V1.ImageContext,Google.Api.Gax.Grpc.CallSettings)">
            <summary>
            Performs "safe search" processing on a single image.
            </summary>
            <remarks>
            If <see cref="T:Google.Cloud.Vision.V1.AnnotateImageException"/> is thrown, the original response can still be retrieved using
            <see cref="P:Google.Cloud.Vision.V1.AnnotateImageException.Response"/>.
            </remarks>
            <param name="image">The image to process. Must not be null.</param>
            <param name="context">Additional contextual information, if any.</param>
            <param name="callSettings">Call settings to apply to the RPC, if any.</param>
            <exception cref="T:Google.Cloud.Vision.V1.AnnotateImageException">The RPC returns a response, but the response contains an error.</exception>
            <returns>The safe search categorization for the image.</returns>
        </member>
        <member name="M:Google.Cloud.Vision.V1.ImageAnnotatorClient.DetectSafeSearchAsync(Google.Cloud.Vision.V1.Image,Google.Cloud.Vision.V1.ImageContext,Google.Api.Gax.Grpc.CallSettings)">
            <summary>
            Performs "safe search" processing on a single image asynchronously.
            </summary>
            <remarks>
            If <see cref="T:Google.Cloud.Vision.V1.AnnotateImageException"/> is thrown, the original response can still be retrieved using
            <see cref="P:Google.Cloud.Vision.V1.AnnotateImageException.Response"/>.
            </remarks>
            <param name="image">The image to process. Must not be null.</param>
            <param name="context">Additional contextual information, if any.</param>
            <param name="callSettings">Call settings to apply to the RPC, if any.</param>
            <exception cref="T:Google.Cloud.Vision.V1.AnnotateImageException">The RPC returns a response, but the response contains an error.</exception>
            <returns>A task representing the asynchronous operation. The task result will be the safe search categorization for the image.</returns>
        </member>
        <member name="M:Google.Cloud.Vision.V1.ImageAnnotatorClient.DetectImageProperties(Google.Cloud.Vision.V1.Image,Google.Cloud.Vision.V1.ImageContext,Google.Api.Gax.Grpc.CallSettings)">
            <summary>
            Performs image property processing on a single image.
            </summary>
            <remarks>
            If <see cref="T:Google.Cloud.Vision.V1.AnnotateImageException"/> is thrown, the original response can still be retrieved using
            <see cref="P:Google.Cloud.Vision.V1.AnnotateImageException.Response"/>.
            </remarks>
            <param name="image">The image to process. Must not be null.</param>
            <param name="context">Additional contextual information, if any.</param>
            <param name="callSettings">Call settings to apply to the RPC, if any.</param>
            <exception cref="T:Google.Cloud.Vision.V1.AnnotateImageException">The RPC returns a response, but the response contains an error.</exception>
            <returns>The detected properties for the image.</returns>
        </member>
        <member name="M:Google.Cloud.Vision.V1.ImageAnnotatorClient.DetectImagePropertiesAsync(Google.Cloud.Vision.V1.Image,Google.Cloud.Vision.V1.ImageContext,Google.Api.Gax.Grpc.CallSettings)">
            <summary>
            Performs image property processing on a single image asynchronously.
            </summary>
            <remarks>
            If <see cref="T:Google.Cloud.Vision.V1.AnnotateImageException"/> is thrown, the original response can still be retrieved using
            <see cref="P:Google.Cloud.Vision.V1.AnnotateImageException.Response"/>.
            </remarks>
            <param name="image">The image to process. Must not be null.</param>
            <param name="context">Additional contextual information, if any.</param>
            <param name="callSettings">Call settings to apply to the RPC, if any.</param>
            <exception cref="T:Google.Cloud.Vision.V1.AnnotateImageException">The RPC returns a response, but the response contains an error.</exception>
            <returns>A task representing the asynchronous operation. The task result will be the detected properties for the image.</returns>
        </member>
        <member name="M:Google.Cloud.Vision.V1.ImageAnnotatorClient.Annotate(Google.Cloud.Vision.V1.AnnotateImageRequest,Google.Api.Gax.Grpc.CallSettings)">
            <summary>
            Annotates a single image.
            </summary>
            <remarks>
            <para>This simply delegates to <see cref="M:Google.Cloud.Vision.V1.ImageAnnotatorClient.BatchAnnotateImages(System.Collections.Generic.IEnumerable{Google.Cloud.Vision.V1.AnnotateImageRequest},Google.Api.Gax.Grpc.CallSettings)"/>
            by creating a batch with a single request, and returns the single response.</para>
            <para>If <see cref="T:Google.Cloud.Vision.V1.AnnotateImageException"/> is thrown, the original response can still be retrieved using
            <see cref="P:Google.Cloud.Vision.V1.AnnotateImageException.Response"/>.
            </para>
            </remarks>
            <param name="request">The annotation request to process. Must not be null.</param>
            <param name="settings">Call settings to apply to the RPC, if any.</param>
            <exception cref="T:Google.Cloud.Vision.V1.AnnotateImageException">The RPC returns a response, but the response contains an error.</exception>
            <returns>The annotation response.</returns>
        </member>
        <member name="M:Google.Cloud.Vision.V1.ImageAnnotatorClient.AnnotateAsync(Google.Cloud.Vision.V1.AnnotateImageRequest,System.Threading.CancellationToken)">
            <summary>
            Annotates a single image asynchronously.
            </summary>
            <remarks>
            <para>This simply delegates to <see cref="M:Google.Cloud.Vision.V1.ImageAnnotatorClient.BatchAnnotateImagesAsync(System.Collections.Generic.IEnumerable{Google.Cloud.Vision.V1.AnnotateImageRequest},Google.Api.Gax.Grpc.CallSettings)"/>
            by creating a batch with a single request, and returns the single response.</para>
            <para>If <see cref="T:Google.Cloud.Vision.V1.AnnotateImageException"/> is thrown, the original response can still be retrieved using
            <see cref="P:Google.Cloud.Vision.V1.AnnotateImageException.Response"/>.</para>
            </remarks>
            <param name="request">The annotation request to process. Must not be null.</param>
            <param name="cancellationToken">A <see cref="T:System.Threading.CancellationToken"/> to use for this RPC.</param>
            <exception cref="T:Google.Cloud.Vision.V1.AnnotateImageException">The RPC returns a response, but the response contains an error.</exception>
            <returns>A task representing the asynchronous operation. The task result will be the annotation response.</returns>
        </member>
        <member name="M:Google.Cloud.Vision.V1.ImageAnnotatorClient.AnnotateAsync(Google.Cloud.Vision.V1.AnnotateImageRequest,Google.Api.Gax.Grpc.CallSettings)">
            <summary>
            Annotates a single image asynchronously.
            </summary>
            <remarks>
            <para>This simply delegates to <see cref="M:Google.Cloud.Vision.V1.ImageAnnotatorClient.BatchAnnotateImagesAsync(System.Collections.Generic.IEnumerable{Google.Cloud.Vision.V1.AnnotateImageRequest},Google.Api.Gax.Grpc.CallSettings)"/>
            by creating a batch with a single request, and returns the single response.</para>
            <para>If <see cref="T:Google.Cloud.Vision.V1.AnnotateImageException"/> is thrown, the original response can still be retrieved using
            <see cref="P:Google.Cloud.Vision.V1.AnnotateImageException.Response"/>.</para>
            </remarks>
            <param name="request">The annotation request to process. Must not be null.</param>
            <param name="settings">Call settings to apply to the RPC, if any.</param>
            <exception cref="T:Google.Cloud.Vision.V1.AnnotateImageException">The RPC returns a response, but the response contains an error.</exception>
            <returns>A task representing the asynchronous operation. The task result will be the annotation response.</returns>
        </member>
        <member name="T:Google.Cloud.Vision.V1.ImageAnnotatorClientImpl">
            <summary>
            ImageAnnotator client wrapper implementation, for convenient use.
            </summary>
        </member>
        <member name="M:Google.Cloud.Vision.V1.ImageAnnotatorClientImpl.#ctor(Google.Cloud.Vision.V1.ImageAnnotator.ImageAnnotatorClient,Google.Cloud.Vision.V1.ImageAnnotatorSettings)">
            <summary>
            Constructs a client wrapper for the ImageAnnotator service, with the specified gRPC client and settings.
            </summary>
            <param name="grpcClient">The underlying gRPC client.</param>
            <param name="settings">The base <see cref="T:Google.Cloud.Vision.V1.ImageAnnotatorSettings"/> used within this client </param>
        </member>
        <member name="P:Google.Cloud.Vision.V1.ImageAnnotatorClientImpl.GrpcClient">
            <summary>
            The underlying gRPC ImageAnnotator client.
            </summary>
        </member>
        <member name="M:Google.Cloud.Vision.V1.ImageAnnotatorClientImpl.BatchAnnotateImagesAsync(Google.Cloud.Vision.V1.BatchAnnotateImagesRequest,Google.Api.Gax.Grpc.CallSettings)">
            <summary>
            Run image detection and annotation for a batch of images.
            </summary>
            <param name="request">
            The request object containing all of the parameters for the API call.
            </param>
            <param name="callSettings">
            If not null, applies overrides to this RPC call.
            </param>
            <returns>
            A Task containing the RPC response.
            </returns>
        </member>
        <member name="M:Google.Cloud.Vision.V1.ImageAnnotatorClientImpl.BatchAnnotateImages(Google.Cloud.Vision.V1.BatchAnnotateImagesRequest,Google.Api.Gax.Grpc.CallSettings)">
            <summary>
            Run image detection and annotation for a batch of images.
            </summary>
            <param name="request">
            The request object containing all of the parameters for the API call.
            </param>
            <param name="callSettings">
            If not null, applies overrides to this RPC call.
            </param>
            <returns>
            The RPC response.
            </returns>
        </member>
        <member name="T:Google.Cloud.Vision.V1.ImageAnnotator">
            <summary>
            Service that performs Google Cloud Vision API detection tasks over client
            images, such as face, landmark, logo, label, and text detection. The
            ImageAnnotator service returns detected entities from the images.
            </summary>
        </member>
        <member name="P:Google.Cloud.Vision.V1.ImageAnnotator.Descriptor">
            <summary>Service descriptor</summary>
        </member>
        <member name="T:Google.Cloud.Vision.V1.ImageAnnotator.ImageAnnotatorBase">
            <summary>Base class for server-side implementations of ImageAnnotator</summary>
        </member>
        <member name="M:Google.Cloud.Vision.V1.ImageAnnotator.ImageAnnotatorBase.BatchAnnotateImages(Google.Cloud.Vision.V1.BatchAnnotateImagesRequest,Grpc.Core.ServerCallContext)">
            <summary>
            Run image detection and annotation for a batch of images.
            </summary>
            <param name="request">The request received from the client.</param>
            <param name="context">The context of the server-side call handler being invoked.</param>
            <returns>The response to send back to the client (wrapped by a task).</returns>
        </member>
        <member name="T:Google.Cloud.Vision.V1.ImageAnnotator.ImageAnnotatorClient">
            <summary>Client for ImageAnnotator</summary>
        </member>
        <member name="M:Google.Cloud.Vision.V1.ImageAnnotator.ImageAnnotatorClient.#ctor(Grpc.Core.Channel)">
            <summary>Creates a new client for ImageAnnotator</summary>
            <param name="channel">The channel to use to make remote calls.</param>
        </member>
        <member name="M:Google.Cloud.Vision.V1.ImageAnnotator.ImageAnnotatorClient.#ctor(Grpc.Core.CallInvoker)">
            <summary>Creates a new client for ImageAnnotator that uses a custom <c>CallInvoker</c>.</summary>
            <param name="callInvoker">The callInvoker to use to make remote calls.</param>
        </member>
        <member name="M:Google.Cloud.Vision.V1.ImageAnnotator.ImageAnnotatorClient.#ctor">
            <summary>Protected parameterless constructor to allow creation of test doubles.</summary>
        </member>
        <member name="M:Google.Cloud.Vision.V1.ImageAnnotator.ImageAnnotatorClient.#ctor(Grpc.Core.ClientBase.ClientBaseConfiguration)">
            <summary>Protected constructor to allow creation of configured clients.</summary>
            <param name="configuration">The client configuration.</param>
        </member>
        <member name="M:Google.Cloud.Vision.V1.ImageAnnotator.ImageAnnotatorClient.BatchAnnotateImages(Google.Cloud.Vision.V1.BatchAnnotateImagesRequest,Grpc.Core.Metadata,System.Nullable{System.DateTime},System.Threading.CancellationToken)">
            <summary>
            Run image detection and annotation for a batch of images.
            </summary>
            <param name="request">The request to send to the server.</param>
            <param name="headers">The initial metadata to send with the call. This parameter is optional.</param>
            <param name="deadline">An optional deadline for the call. The call will be cancelled if deadline is hit.</param>
            <param name="cancellationToken">An optional token for canceling the call.</param>
            <returns>The response received from the server.</returns>
        </member>
        <member name="M:Google.Cloud.Vision.V1.ImageAnnotator.ImageAnnotatorClient.BatchAnnotateImages(Google.Cloud.Vision.V1.BatchAnnotateImagesRequest,Grpc.Core.CallOptions)">
            <summary>
            Run image detection and annotation for a batch of images.
            </summary>
            <param name="request">The request to send to the server.</param>
            <param name="options">The options for the call.</param>
            <returns>The response received from the server.</returns>
        </member>
        <member name="M:Google.Cloud.Vision.V1.ImageAnnotator.ImageAnnotatorClient.BatchAnnotateImagesAsync(Google.Cloud.Vision.V1.BatchAnnotateImagesRequest,Grpc.Core.Metadata,System.Nullable{System.DateTime},System.Threading.CancellationToken)">
            <summary>
            Run image detection and annotation for a batch of images.
            </summary>
            <param name="request">The request to send to the server.</param>
            <param name="headers">The initial metadata to send with the call. This parameter is optional.</param>
            <param name="deadline">An optional deadline for the call. The call will be cancelled if deadline is hit.</param>
            <param name="cancellationToken">An optional token for canceling the call.</param>
            <returns>The call object.</returns>
        </member>
        <member name="M:Google.Cloud.Vision.V1.ImageAnnotator.ImageAnnotatorClient.BatchAnnotateImagesAsync(Google.Cloud.Vision.V1.BatchAnnotateImagesRequest,Grpc.Core.CallOptions)">
            <summary>
            Run image detection and annotation for a batch of images.
            </summary>
            <param name="request">The request to send to the server.</param>
            <param name="options">The options for the call.</param>
            <returns>The call object.</returns>
        </member>
        <member name="M:Google.Cloud.Vision.V1.ImageAnnotator.ImageAnnotatorClient.NewInstance(Grpc.Core.ClientBase.ClientBaseConfiguration)">
            <summary>Creates a new instance of client from given <c>ClientBaseConfiguration</c>.</summary>
        </member>
        <member name="M:Google.Cloud.Vision.V1.ImageAnnotator.BindService(Google.Cloud.Vision.V1.ImageAnnotator.ImageAnnotatorBase)">
            <summary>Creates service definition that can be registered with a server</summary>
            <param name="serviceImpl">An object implementing the server-side handling logic.</param>
        </member>
        <member name="T:Google.Cloud.Vision.V1.TextAnnotationReflection">
            <summary>Holder for reflection information generated from google/cloud/vision/v1/text_annotation.proto</summary>
        </member>
        <member name="P:Google.Cloud.Vision.V1.TextAnnotationReflection.Descriptor">
            <summary>File descriptor for google/cloud/vision/v1/text_annotation.proto</summary>
        </member>
        <member name="T:Google.Cloud.Vision.V1.TextAnnotation">
            <summary>
            TextAnnotation contains a structured representation of OCR extracted text.
            The hierarchy of an OCR extracted text structure is like this:
                TextAnnotation -> Page -> Block -> Paragraph -> Word -> Symbol
            Each structural component, starting from Page, may further have their own
            properties. Properties describe detected languages, breaks etc.. Please refer
            to the [TextAnnotation.TextProperty][google.cloud.vision.v1.TextAnnotation.TextProperty] message definition below for more
            detail.
            </summary>
        </member>
        <member name="F:Google.Cloud.Vision.V1.TextAnnotation.PagesFieldNumber">
            <summary>Field number for the "pages" field.</summary>
        </member>
        <member name="P:Google.Cloud.Vision.V1.TextAnnotation.Pages">
            <summary>
            List of pages detected by OCR.
            </summary>
        </member>
        <member name="F:Google.Cloud.Vision.V1.TextAnnotation.TextFieldNumber">
            <summary>Field number for the "text" field.</summary>
        </member>
        <member name="P:Google.Cloud.Vision.V1.TextAnnotation.Text">
            <summary>
            UTF-8 text detected on the pages.
            </summary>
        </member>
        <member name="T:Google.Cloud.Vision.V1.TextAnnotation.Types">
            <summary>Container for nested types declared in the TextAnnotation message type.</summary>
        </member>
        <member name="T:Google.Cloud.Vision.V1.TextAnnotation.Types.DetectedLanguage">
            <summary>
            Detected language for a structural component.
            </summary>
        </member>
        <member name="F:Google.Cloud.Vision.V1.TextAnnotation.Types.DetectedLanguage.LanguageCodeFieldNumber">
            <summary>Field number for the "language_code" field.</summary>
        </member>
        <member name="P:Google.Cloud.Vision.V1.TextAnnotation.Types.DetectedLanguage.LanguageCode">
            <summary>
            The BCP-47 language code, such as "en-US" or "sr-Latn". For more
            information, see
            http://www.unicode.org/reports/tr35/#Unicode_locale_identifier.
            </summary>
        </member>
        <member name="F:Google.Cloud.Vision.V1.TextAnnotation.Types.DetectedLanguage.ConfidenceFieldNumber">
            <summary>Field number for the "confidence" field.</summary>
        </member>
        <member name="P:Google.Cloud.Vision.V1.TextAnnotation.Types.DetectedLanguage.Confidence">
            <summary>
            Confidence of detected language. Range [0, 1].
            </summary>
        </member>
        <member name="T:Google.Cloud.Vision.V1.TextAnnotation.Types.DetectedBreak">
            <summary>
            Detected start or end of a structural component.
            </summary>
        </member>
        <member name="F:Google.Cloud.Vision.V1.TextAnnotation.Types.DetectedBreak.TypeFieldNumber">
            <summary>Field number for the "type" field.</summary>
        </member>
        <member name="P:Google.Cloud.Vision.V1.TextAnnotation.Types.DetectedBreak.Type">
            <summary>
            Detected break type.
            </summary>
        </member>
        <member name="F:Google.Cloud.Vision.V1.TextAnnotation.Types.DetectedBreak.IsPrefixFieldNumber">
            <summary>Field number for the "is_prefix" field.</summary>
        </member>
        <member name="P:Google.Cloud.Vision.V1.TextAnnotation.Types.DetectedBreak.IsPrefix">
            <summary>
            True if break prepends the element.
            </summary>
        </member>
        <member name="T:Google.Cloud.Vision.V1.TextAnnotation.Types.DetectedBreak.Types">
            <summary>Container for nested types declared in the DetectedBreak message type.</summary>
        </member>
        <member name="T:Google.Cloud.Vision.V1.TextAnnotation.Types.DetectedBreak.Types.BreakType">
            <summary>
            Enum to denote the type of break found. New line, space etc.
            </summary>
        </member>
        <member name="F:Google.Cloud.Vision.V1.TextAnnotation.Types.DetectedBreak.Types.BreakType.Unknown">
            <summary>
            Unknown break label type.
            </summary>
        </member>
        <member name="F:Google.Cloud.Vision.V1.TextAnnotation.Types.DetectedBreak.Types.BreakType.Space">
            <summary>
            Regular space.
            </summary>
        </member>
        <member name="F:Google.Cloud.Vision.V1.TextAnnotation.Types.DetectedBreak.Types.BreakType.SureSpace">
            <summary>
            Sure space (very wide).
            </summary>
        </member>
        <member name="F:Google.Cloud.Vision.V1.TextAnnotation.Types.DetectedBreak.Types.BreakType.EolSureSpace">
            <summary>
            Line-wrapping break.
            </summary>
        </member>
        <member name="F:Google.Cloud.Vision.V1.TextAnnotation.Types.DetectedBreak.Types.BreakType.Hyphen">
            <summary>
            End-line hyphen that is not present in text; does not co-occur with
            `SPACE`, `LEADER_SPACE`, or `LINE_BREAK`.
            </summary>
        </member>
        <member name="F:Google.Cloud.Vision.V1.TextAnnotation.Types.DetectedBreak.Types.BreakType.LineBreak">
            <summary>
            Line break that ends a paragraph.
            </summary>
        </member>
        <member name="T:Google.Cloud.Vision.V1.TextAnnotation.Types.TextProperty">
            <summary>
            Additional information detected on the structural component.
            </summary>
        </member>
        <member name="F:Google.Cloud.Vision.V1.TextAnnotation.Types.TextProperty.DetectedLanguagesFieldNumber">
            <summary>Field number for the "detected_languages" field.</summary>
        </member>
        <member name="P:Google.Cloud.Vision.V1.TextAnnotation.Types.TextProperty.DetectedLanguages">
            <summary>
            A list of detected languages together with confidence.
            </summary>
        </member>
        <member name="F:Google.Cloud.Vision.V1.TextAnnotation.Types.TextProperty.DetectedBreakFieldNumber">
            <summary>Field number for the "detected_break" field.</summary>
        </member>
        <member name="P:Google.Cloud.Vision.V1.TextAnnotation.Types.TextProperty.DetectedBreak">
            <summary>
            Detected start or end of a text segment.
            </summary>
        </member>
        <member name="T:Google.Cloud.Vision.V1.Page">
            <summary>
            Detected page from OCR.
            </summary>
        </member>
        <member name="F:Google.Cloud.Vision.V1.Page.PropertyFieldNumber">
            <summary>Field number for the "property" field.</summary>
        </member>
        <member name="P:Google.Cloud.Vision.V1.Page.Property">
            <summary>
            Additional information detected on the page.
            </summary>
        </member>
        <member name="F:Google.Cloud.Vision.V1.Page.WidthFieldNumber">
            <summary>Field number for the "width" field.</summary>
        </member>
        <member name="P:Google.Cloud.Vision.V1.Page.Width">
            <summary>
            Page width in pixels.
            </summary>
        </member>
        <member name="F:Google.Cloud.Vision.V1.Page.HeightFieldNumber">
            <summary>Field number for the "height" field.</summary>
        </member>
        <member name="P:Google.Cloud.Vision.V1.Page.Height">
            <summary>
            Page height in pixels.
            </summary>
        </member>
        <member name="F:Google.Cloud.Vision.V1.Page.BlocksFieldNumber">
            <summary>Field number for the "blocks" field.</summary>
        </member>
        <member name="P:Google.Cloud.Vision.V1.Page.Blocks">
            <summary>
            List of blocks of text, images etc on this page.
            </summary>
        </member>
        <member name="F:Google.Cloud.Vision.V1.Page.ConfidenceFieldNumber">
            <summary>Field number for the "confidence" field.</summary>
        </member>
        <member name="P:Google.Cloud.Vision.V1.Page.Confidence">
            <summary>
            Confidence of the OCR results on the page. Range [0, 1].
            </summary>
        </member>
        <member name="T:Google.Cloud.Vision.V1.Block">
            <summary>
            Logical element on the page.
            </summary>
        </member>
        <member name="F:Google.Cloud.Vision.V1.Block.PropertyFieldNumber">
            <summary>Field number for the "property" field.</summary>
        </member>
        <member name="P:Google.Cloud.Vision.V1.Block.Property">
            <summary>
            Additional information detected for the block.
            </summary>
        </member>
        <member name="F:Google.Cloud.Vision.V1.Block.BoundingBoxFieldNumber">
            <summary>Field number for the "bounding_box" field.</summary>
        </member>
        <member name="P:Google.Cloud.Vision.V1.Block.BoundingBox">
             <summary>
             The bounding box for the block.
             The vertices are in the order of top-left, top-right, bottom-right,
             bottom-left. When a rotation of the bounding box is detected the rotation
             is represented as around the top-left corner as defined when the text is
             read in the 'natural' orientation.
             For example:
            
             * when the text is horizontal it might look like:
            
                     0----1
                     |    |
                     3----2
            
             * when it's rotated 180 degrees around the top-left corner it becomes:
            
                     2----3
                     |    |
                     1----0
            
               and the vertice order will still be (0, 1, 2, 3).
             </summary>
        </member>
        <member name="F:Google.Cloud.Vision.V1.Block.ParagraphsFieldNumber">
            <summary>Field number for the "paragraphs" field.</summary>
        </member>
        <member name="P:Google.Cloud.Vision.V1.Block.Paragraphs">
            <summary>
            List of paragraphs in this block (if this blocks is of type text).
            </summary>
        </member>
        <member name="F:Google.Cloud.Vision.V1.Block.BlockTypeFieldNumber">
            <summary>Field number for the "block_type" field.</summary>
        </member>
        <member name="P:Google.Cloud.Vision.V1.Block.BlockType">
            <summary>
            Detected block type (text, image etc) for this block.
            </summary>
        </member>
        <member name="F:Google.Cloud.Vision.V1.Block.ConfidenceFieldNumber">
            <summary>Field number for the "confidence" field.</summary>
        </member>
        <member name="P:Google.Cloud.Vision.V1.Block.Confidence">
            <summary>
            Confidence of the OCR results on the block. Range [0, 1].
            </summary>
        </member>
        <member name="T:Google.Cloud.Vision.V1.Block.Types">
            <summary>Container for nested types declared in the Block message type.</summary>
        </member>
        <member name="T:Google.Cloud.Vision.V1.Block.Types.BlockType">
            <summary>
            Type of a block (text, image etc) as identified by OCR.
            </summary>
        </member>
        <member name="F:Google.Cloud.Vision.V1.Block.Types.BlockType.Unknown">
            <summary>
            Unknown block type.
            </summary>
        </member>
        <member name="F:Google.Cloud.Vision.V1.Block.Types.BlockType.Text">
            <summary>
            Regular text block.
            </summary>
        </member>
        <member name="F:Google.Cloud.Vision.V1.Block.Types.BlockType.Table">
            <summary>
            Table block.
            </summary>
        </member>
        <member name="F:Google.Cloud.Vision.V1.Block.Types.BlockType.Picture">
            <summary>
            Image block.
            </summary>
        </member>
        <member name="F:Google.Cloud.Vision.V1.Block.Types.BlockType.Ruler">
            <summary>
            Horizontal/vertical line box.
            </summary>
        </member>
        <member name="F:Google.Cloud.Vision.V1.Block.Types.BlockType.Barcode">
            <summary>
            Barcode block.
            </summary>
        </member>
        <member name="T:Google.Cloud.Vision.V1.Paragraph">
            <summary>
            Structural unit of text representing a number of words in certain order.
            </summary>
        </member>
        <member name="F:Google.Cloud.Vision.V1.Paragraph.PropertyFieldNumber">
            <summary>Field number for the "property" field.</summary>
        </member>
        <member name="P:Google.Cloud.Vision.V1.Paragraph.Property">
            <summary>
            Additional information detected for the paragraph.
            </summary>
        </member>
        <member name="F:Google.Cloud.Vision.V1.Paragraph.BoundingBoxFieldNumber">
            <summary>Field number for the "bounding_box" field.</summary>
        </member>
        <member name="P:Google.Cloud.Vision.V1.Paragraph.BoundingBox">
            <summary>
            The bounding box for the paragraph.
            The vertices are in the order of top-left, top-right, bottom-right,
            bottom-left. When a rotation of the bounding box is detected the rotation
            is represented as around the top-left corner as defined when the text is
            read in the 'natural' orientation.
            For example:
              * when the text is horizontal it might look like:
                 0----1
                 |    |
                 3----2
              * when it's rotated 180 degrees around the top-left corner it becomes:
                 2----3
                 |    |
                 1----0
              and the vertice order will still be (0, 1, 2, 3).
            </summary>
        </member>
        <member name="F:Google.Cloud.Vision.V1.Paragraph.WordsFieldNumber">
            <summary>Field number for the "words" field.</summary>
        </member>
        <member name="P:Google.Cloud.Vision.V1.Paragraph.Words">
            <summary>
            List of words in this paragraph.
            </summary>
        </member>
        <member name="F:Google.Cloud.Vision.V1.Paragraph.ConfidenceFieldNumber">
            <summary>Field number for the "confidence" field.</summary>
        </member>
        <member name="P:Google.Cloud.Vision.V1.Paragraph.Confidence">
            <summary>
            Confidence of the OCR results for the paragraph. Range [0, 1].
            </summary>
        </member>
        <member name="T:Google.Cloud.Vision.V1.Word">
            <summary>
            A word representation.
            </summary>
        </member>
        <member name="F:Google.Cloud.Vision.V1.Word.PropertyFieldNumber">
            <summary>Field number for the "property" field.</summary>
        </member>
        <member name="P:Google.Cloud.Vision.V1.Word.Property">
            <summary>
            Additional information detected for the word.
            </summary>
        </member>
        <member name="F:Google.Cloud.Vision.V1.Word.BoundingBoxFieldNumber">
            <summary>Field number for the "bounding_box" field.</summary>
        </member>
        <member name="P:Google.Cloud.Vision.V1.Word.BoundingBox">
            <summary>
            The bounding box for the word.
            The vertices are in the order of top-left, top-right, bottom-right,
            bottom-left. When a rotation of the bounding box is detected the rotation
            is represented as around the top-left corner as defined when the text is
            read in the 'natural' orientation.
            For example:
              * when the text is horizontal it might look like:
                 0----1
                 |    |
                 3----2
              * when it's rotated 180 degrees around the top-left corner it becomes:
                 2----3
                 |    |
                 1----0
              and the vertice order will still be (0, 1, 2, 3).
            </summary>
        </member>
        <member name="F:Google.Cloud.Vision.V1.Word.SymbolsFieldNumber">
            <summary>Field number for the "symbols" field.</summary>
        </member>
        <member name="P:Google.Cloud.Vision.V1.Word.Symbols">
            <summary>
            List of symbols in the word.
            The order of the symbols follows the natural reading order.
            </summary>
        </member>
        <member name="F:Google.Cloud.Vision.V1.Word.ConfidenceFieldNumber">
            <summary>Field number for the "confidence" field.</summary>
        </member>
        <member name="P:Google.Cloud.Vision.V1.Word.Confidence">
            <summary>
            Confidence of the OCR results for the word. Range [0, 1].
            </summary>
        </member>
        <member name="T:Google.Cloud.Vision.V1.Symbol">
            <summary>
            A single symbol representation.
            </summary>
        </member>
        <member name="F:Google.Cloud.Vision.V1.Symbol.PropertyFieldNumber">
            <summary>Field number for the "property" field.</summary>
        </member>
        <member name="P:Google.Cloud.Vision.V1.Symbol.Property">
            <summary>
            Additional information detected for the symbol.
            </summary>
        </member>
        <member name="F:Google.Cloud.Vision.V1.Symbol.BoundingBoxFieldNumber">
            <summary>Field number for the "bounding_box" field.</summary>
        </member>
        <member name="P:Google.Cloud.Vision.V1.Symbol.BoundingBox">
            <summary>
            The bounding box for the symbol.
            The vertices are in the order of top-left, top-right, bottom-right,
            bottom-left. When a rotation of the bounding box is detected the rotation
            is represented as around the top-left corner as defined when the text is
            read in the 'natural' orientation.
            For example:
              * when the text is horizontal it might look like:
                 0----1
                 |    |
                 3----2
              * when it's rotated 180 degrees around the top-left corner it becomes:
                 2----3
                 |    |
                 1----0
              and the vertice order will still be (0, 1, 2, 3).
            </summary>
        </member>
        <member name="F:Google.Cloud.Vision.V1.Symbol.TextFieldNumber">
            <summary>Field number for the "text" field.</summary>
        </member>
        <member name="P:Google.Cloud.Vision.V1.Symbol.Text">
            <summary>
            The actual UTF-8 representation of the symbol.
            </summary>
        </member>
        <member name="F:Google.Cloud.Vision.V1.Symbol.ConfidenceFieldNumber">
            <summary>Field number for the "confidence" field.</summary>
        </member>
        <member name="P:Google.Cloud.Vision.V1.Symbol.Confidence">
            <summary>
            Confidence of the OCR results for the symbol. Range [0, 1].
            </summary>
        </member>
        <member name="T:Google.Cloud.Vision.V1.WebDetectionReflection">
            <summary>Holder for reflection information generated from google/cloud/vision/v1/web_detection.proto</summary>
        </member>
        <member name="P:Google.Cloud.Vision.V1.WebDetectionReflection.Descriptor">
            <summary>File descriptor for google/cloud/vision/v1/web_detection.proto</summary>
        </member>
        <member name="T:Google.Cloud.Vision.V1.WebDetection">
            <summary>
            Relevant information for the image from the Internet.
            </summary>
        </member>
        <member name="F:Google.Cloud.Vision.V1.WebDetection.WebEntitiesFieldNumber">
            <summary>Field number for the "web_entities" field.</summary>
        </member>
        <member name="P:Google.Cloud.Vision.V1.WebDetection.WebEntities">
            <summary>
            Deduced entities from similar images on the Internet.
            </summary>
        </member>
        <member name="F:Google.Cloud.Vision.V1.WebDetection.FullMatchingImagesFieldNumber">
            <summary>Field number for the "full_matching_images" field.</summary>
        </member>
        <member name="P:Google.Cloud.Vision.V1.WebDetection.FullMatchingImages">
            <summary>
            Fully matching images from the Internet.
            Can include resized copies of the query image.
            </summary>
        </member>
        <member name="F:Google.Cloud.Vision.V1.WebDetection.PartialMatchingImagesFieldNumber">
            <summary>Field number for the "partial_matching_images" field.</summary>
        </member>
        <member name="P:Google.Cloud.Vision.V1.WebDetection.PartialMatchingImages">
            <summary>
            Partial matching images from the Internet.
            Those images are similar enough to share some key-point features. For
            example an original image will likely have partial matching for its crops.
            </summary>
        </member>
        <member name="F:Google.Cloud.Vision.V1.WebDetection.PagesWithMatchingImagesFieldNumber">
            <summary>Field number for the "pages_with_matching_images" field.</summary>
        </member>
        <member name="P:Google.Cloud.Vision.V1.WebDetection.PagesWithMatchingImages">
            <summary>
            Web pages containing the matching images from the Internet.
            </summary>
        </member>
        <member name="F:Google.Cloud.Vision.V1.WebDetection.VisuallySimilarImagesFieldNumber">
            <summary>Field number for the "visually_similar_images" field.</summary>
        </member>
        <member name="P:Google.Cloud.Vision.V1.WebDetection.VisuallySimilarImages">
            <summary>
            The visually similar image results.
            </summary>
        </member>
        <member name="F:Google.Cloud.Vision.V1.WebDetection.BestGuessLabelsFieldNumber">
            <summary>Field number for the "best_guess_labels" field.</summary>
        </member>
        <member name="P:Google.Cloud.Vision.V1.WebDetection.BestGuessLabels">
            <summary>
            Best guess text labels for the request image.
            </summary>
        </member>
        <member name="T:Google.Cloud.Vision.V1.WebDetection.Types">
            <summary>Container for nested types declared in the WebDetection message type.</summary>
        </member>
        <member name="T:Google.Cloud.Vision.V1.WebDetection.Types.WebEntity">
            <summary>
            Entity deduced from similar images on the Internet.
            </summary>
        </member>
        <member name="F:Google.Cloud.Vision.V1.WebDetection.Types.WebEntity.EntityIdFieldNumber">
            <summary>Field number for the "entity_id" field.</summary>
        </member>
        <member name="P:Google.Cloud.Vision.V1.WebDetection.Types.WebEntity.EntityId">
            <summary>
            Opaque entity ID.
            </summary>
        </member>
        <member name="F:Google.Cloud.Vision.V1.WebDetection.Types.WebEntity.ScoreFieldNumber">
            <summary>Field number for the "score" field.</summary>
        </member>
        <member name="P:Google.Cloud.Vision.V1.WebDetection.Types.WebEntity.Score">
            <summary>
            Overall relevancy score for the entity.
            Not normalized and not comparable across different image queries.
            </summary>
        </member>
        <member name="F:Google.Cloud.Vision.V1.WebDetection.Types.WebEntity.DescriptionFieldNumber">
            <summary>Field number for the "description" field.</summary>
        </member>
        <member name="P:Google.Cloud.Vision.V1.WebDetection.Types.WebEntity.Description">
            <summary>
            Canonical description of the entity, in English.
            </summary>
        </member>
        <member name="T:Google.Cloud.Vision.V1.WebDetection.Types.WebImage">
            <summary>
            Metadata for online images.
            </summary>
        </member>
        <member name="F:Google.Cloud.Vision.V1.WebDetection.Types.WebImage.UrlFieldNumber">
            <summary>Field number for the "url" field.</summary>
        </member>
        <member name="P:Google.Cloud.Vision.V1.WebDetection.Types.WebImage.Url">
            <summary>
            The result image URL.
            </summary>
        </member>
        <member name="F:Google.Cloud.Vision.V1.WebDetection.Types.WebImage.ScoreFieldNumber">
            <summary>Field number for the "score" field.</summary>
        </member>
        <member name="P:Google.Cloud.Vision.V1.WebDetection.Types.WebImage.Score">
            <summary>
            (Deprecated) Overall relevancy score for the image.
            </summary>
        </member>
        <member name="T:Google.Cloud.Vision.V1.WebDetection.Types.WebPage">
            <summary>
            Metadata for web pages.
            </summary>
        </member>
        <member name="F:Google.Cloud.Vision.V1.WebDetection.Types.WebPage.UrlFieldNumber">
            <summary>Field number for the "url" field.</summary>
        </member>
        <member name="P:Google.Cloud.Vision.V1.WebDetection.Types.WebPage.Url">
            <summary>
            The result web page URL.
            </summary>
        </member>
        <member name="F:Google.Cloud.Vision.V1.WebDetection.Types.WebPage.ScoreFieldNumber">
            <summary>Field number for the "score" field.</summary>
        </member>
        <member name="P:Google.Cloud.Vision.V1.WebDetection.Types.WebPage.Score">
            <summary>
            (Deprecated) Overall relevancy score for the web page.
            </summary>
        </member>
        <member name="F:Google.Cloud.Vision.V1.WebDetection.Types.WebPage.PageTitleFieldNumber">
            <summary>Field number for the "page_title" field.</summary>
        </member>
        <member name="P:Google.Cloud.Vision.V1.WebDetection.Types.WebPage.PageTitle">
            <summary>
            Title for the web page, may contain HTML markups.
            </summary>
        </member>
        <member name="F:Google.Cloud.Vision.V1.WebDetection.Types.WebPage.FullMatchingImagesFieldNumber">
            <summary>Field number for the "full_matching_images" field.</summary>
        </member>
        <member name="P:Google.Cloud.Vision.V1.WebDetection.Types.WebPage.FullMatchingImages">
            <summary>
            Fully matching images on the page.
            Can include resized copies of the query image.
            </summary>
        </member>
        <member name="F:Google.Cloud.Vision.V1.WebDetection.Types.WebPage.PartialMatchingImagesFieldNumber">
            <summary>Field number for the "partial_matching_images" field.</summary>
        </member>
        <member name="P:Google.Cloud.Vision.V1.WebDetection.Types.WebPage.PartialMatchingImages">
            <summary>
            Partial matching images on the page.
            Those images are similar enough to share some key-point features. For
            example an original image will likely have partial matching for its
            crops.
            </summary>
        </member>
        <member name="T:Google.Cloud.Vision.V1.WebDetection.Types.WebLabel">
            <summary>
            Label to provide extra metadata for the web detection.
            </summary>
        </member>
        <member name="F:Google.Cloud.Vision.V1.WebDetection.Types.WebLabel.LabelFieldNumber">
            <summary>Field number for the "label" field.</summary>
        </member>
        <member name="P:Google.Cloud.Vision.V1.WebDetection.Types.WebLabel.Label">
            <summary>
            Label for extra metadata.
            </summary>
        </member>
        <member name="F:Google.Cloud.Vision.V1.WebDetection.Types.WebLabel.LanguageCodeFieldNumber">
            <summary>Field number for the "language_code" field.</summary>
        </member>
        <member name="P:Google.Cloud.Vision.V1.WebDetection.Types.WebLabel.LanguageCode">
            <summary>
            The BCP-47 language code for `label`, such as "en-US" or "sr-Latn".
            For more information, see
            http://www.unicode.org/reports/tr35/#Unicode_locale_identifier.
            </summary>
        </member>
    </members>
</doc>
